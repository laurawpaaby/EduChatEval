{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Lauras Python Package","text":"<p>If your interested in evaluating the usage of bots in education yay </p>"},{"location":"about/","title":"About","text":""},{"location":"about/#project","title":"Project","text":"<p>This package was developed as part of a master\u2019s thesis on the MSc in Cognitive Science at Aarhus University. With this package, I hope to contribute to the development of methods for evaluating the use of LLMs.</p> <p>The main contribution is refining and wrapping existing methods into a coherent test suite. Additionally, we have introduced our own evaluation and visualization functions to present the results of various metrics in a cohesive manner.</p>"},{"location":"about/#contact","title":"Contact","text":"<p>If you have any questions regarding the project or the code implementation, feel free to contact someone@example.com.</p> <p>Chatwrap is licensed under MIT and available on GitHub.</p>"},{"location":"about/#acknowledgements","title":"Acknowledgements","text":"<p>This project uses code from three already implemented frameworks for quantifying gender bias in Danish. While all externally authored code is properly attributed in the repository\u2019s scripts, we would also like to acknowledge the authors of the work we draw on:</p> <p>Reference 1: Author, A. A. (Year). Title of the article. Journal Title, 10(2), 123\u2013145. https://doi.org/10.0000/xyz123 Reference 2: Author, B. B., &amp; Author, C. C. (Year). Another work. Publisher. https://doi.org/10.0000/abc456 Reference 3: Author, D. D. (Year). Yet another reference. Conference Proceedings. https://doi.org/10.0000/def789 Reference 4: Organization E. (Year). Document title. Retrieved from https://doi.org/10.0000/ghi012</p>"},{"location":"installation/","title":"Installation","text":"<p>You can install chat wrappy using via pip from PyPI:</p> <p><code>pip install chat-wrappy</code></p> <p>Or from Github:</p> <p><code>pip install git+https://github.com/laurawpaaby/EduChatEval.git</code></p>"},{"location":"api/api_frame_gen/","title":"Framework Generator","text":""},{"location":"api/api_frame_gen/#educhateval.core.FrameworkGenerator","title":"<code>educhateval.core.FrameworkGenerator</code>","text":"<p>Module for generating synthetic annotated datasets (frameworks) using instruction-tuned models hosted locally and filtering of low-quality examples via classifier agreement.</p> <p>Attributes:</p> Name Type Description <code>model_name</code> <code>str</code> <p>Name of the local model to use for generation (default: \"llama-3.2-3b-instruct\").</p> <code>api_url</code> <code>str</code> <p>URL for the local model API (default: \"http://localhost:1234/v1/completions\").</p> <p>Methods:</p> Name Description <code>generate_framework</code> <p>Simulates a dialogue and returns it as a pandas DataFrame.</p> <code>filter_with_classifier</code> <p>Filters the generated dataset using a small classifier trained on real labeled data.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>class FrameworkGenerator:\n    \"\"\"\n    Module for generating synthetic annotated datasets (frameworks) using instruction-tuned models hosted locally and filtering of low-quality examples via classifier agreement.\n\n    Attributes:\n        model_name (str): Name of the local model to use for generation (default: \"llama-3.2-3b-instruct\").\n        api_url (str): URL for the local model API (default: \"http://localhost:1234/v1/completions\").\n\n    Methods:\n        generate_framework(...): Simulates a dialogue and returns it as a pandas DataFrame.\n        filter_with_classifier(...): Filters the generated dataset using a small classifier trained on real labeled data.\n    \"\"\"\n\n    def __init__(\n        self,\n        model_name: str = \"llama-3.2-3b-instruct\",\n        api_url: str = \"http://localhost:1234/v1/completions\",\n    ):\n        self.model_name = model_name\n        self.api_url = api_url\n\n    def generate_framework(\n        self,\n        prompt_path: str = None,\n        prompt_dict_input: dict = None,\n        num_samples: int = 500,\n        json_out: str = None,\n        csv_out: str = None,\n        seed: int = 42,\n        temperature: float = 0.85,\n        top_p: float = 0.90,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Generate a synthetic labeled dataset from prompts using a language model.\n        Either `prompt_path` (path to .py file with `prompt_dict`) or `prompt_dict_input` must be provided.\n\n        Parameters:\n            prompt_path (str): Path to a Python file containing a prompt dictionary.\n            prompt_dict_input (dict): Prompt dictionary directly provided.\n            num_samples (int): Number of samples to generate per category.\n            json_out (str): Optional path to save JSON output.\n            csv_out (str): Optional path to save CSV output.\n            seed (int): Random seed for reproducibility.\n\n        Returns:\n            pd.DataFrame: Cleaned, labeled synthetic dataset.\n        \"\"\"\n        if not prompt_path and not prompt_dict_input:\n            raise ValueError(\n                \"You must provide either a prompt_path or prompt_dict_input.\"\n            )\n\n        set_seed(seed)\n\n        df = synthesize_dataset(\n            prompt_dict=prompt_dict_input,\n            prompt_path=prompt_path,\n            model_name=self.model_name,\n            num_samples=num_samples,\n            api_url=self.api_url,\n            json_out=json_out,\n            csv_out=csv_out,\n            temperature=temperature,\n            top_p=top_p,\n        )\n\n        return df\n\n    #### 2. function to quality check the dataset\n    def filter_with_classifier(\n        self,\n        train_data: Union[str, pd.DataFrame],\n        synth_data: Union[str, pd.DataFrame],\n        text_column: str = \"text\",\n        label_column: str = \"category\",\n        split_ratio: float = 0.2,\n        training_params: list = [0.01, \"cross_entropy\", 5e-5, 8, 8, 4, 0.01],\n        tuning: bool = False,\n        tuning_params: dict = None,\n        model_save_path: str = None,\n        classifier_model_name: str = \"distilbert-base-uncased\",\n        filtered_save_path: str = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Train a small classifier on real labeled data and use it to filter the synthetic dataset by agreement.\n\n        Parameters:\n            train_data (str or pd.DataFrame): Path or DataFrame of small labeled training set.\n            synth_data (str or pd.DataFrame): Path or DataFrame of generated synthetic dataset.\n            text_column (str): Name of the text column.\n            label_column (str): Name of the label column.\n            split_ratio (float): Ratio for train/test split.\n            training_params (list): Training hyperparameters.\n            tuning (bool): Whether to perform hyperparameter tuning using Optuna.\n            tuning_params (dict): Optional tuning grid.\n            model_save_path (str): Optional path to save the classifier model.\n            classifier_model_name (str): HF model ID for the classifier.\n            filtered_save_path (str): Optional path to save filtered synthetic dataset.\n\n        Returns:\n            pd.DataFrame: Filtered synthetic dataset based on classifier agreement.\n        \"\"\"\n        if isinstance(train_data, pd.DataFrame) and train_data.empty:\n            raise ValueError(\"Provided training DataFrame is empty.\")\n        if isinstance(synth_data, pd.DataFrame) and synth_data.empty:\n            raise ValueError(\"Provided synthetic DataFrame is empty.\")\n\n        tokenizer = load_tokenizer(classifier_model_name)\n\n        dataset_dict, label2id = load_and_prepare_dataset(\n            train_data, text_column, label_column, split_ratio\n        )\n\n        tokenized = tokenize_dataset(dataset_dict, tokenizer)\n\n        model, trainer = train_model(\n            tokenized,\n            classifier_model_name,\n            len(label2id),\n            training_params,\n            tuning,\n            tuning_params,\n        )\n\n        trainer.evaluate()\n\n        if model_save_path:\n            save_model_and_tokenizer(model, tokenizer, model_save_path)\n\n        df_filtered = filter_synthesized_data(\n            synth_input=synth_data,\n            model=model,\n            tokenizer=tokenizer,\n            label_column=label_column,\n            save_path=filtered_save_path,\n        )\n\n        return df_filtered\n</code></pre>"},{"location":"api/api_frame_gen/#educhateval.core.FrameworkGenerator.model_name","title":"<code>model_name = model_name</code>  <code>instance-attribute</code>","text":""},{"location":"api/api_frame_gen/#educhateval.core.FrameworkGenerator.api_url","title":"<code>api_url = api_url</code>  <code>instance-attribute</code>","text":""},{"location":"api/api_frame_gen/#educhateval.core.FrameworkGenerator.__init__","title":"<code>__init__(model_name='llama-3.2-3b-instruct', api_url='http://localhost:1234/v1/completions')</code>","text":"Source code in <code>src/educhateval/core.py</code> <pre><code>def __init__(\n    self,\n    model_name: str = \"llama-3.2-3b-instruct\",\n    api_url: str = \"http://localhost:1234/v1/completions\",\n):\n    self.model_name = model_name\n    self.api_url = api_url\n</code></pre>"},{"location":"api/api_frame_gen/#educhateval.core.FrameworkGenerator.generate_framework","title":"<code>generate_framework(prompt_path=None, prompt_dict_input=None, num_samples=500, json_out=None, csv_out=None, seed=42, temperature=0.85, top_p=0.9)</code>","text":"<p>Generate a synthetic labeled dataset from prompts using a language model. Either <code>prompt_path</code> (path to .py file with <code>prompt_dict</code>) or <code>prompt_dict_input</code> must be provided.</p> <p>Parameters:</p> Name Type Description Default <code>prompt_path</code> <code>str</code> <p>Path to a Python file containing a prompt dictionary.</p> <code>None</code> <code>prompt_dict_input</code> <code>dict</code> <p>Prompt dictionary directly provided.</p> <code>None</code> <code>num_samples</code> <code>int</code> <p>Number of samples to generate per category.</p> <code>500</code> <code>json_out</code> <code>str</code> <p>Optional path to save JSON output.</p> <code>None</code> <code>csv_out</code> <code>str</code> <p>Optional path to save CSV output.</p> <code>None</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>42</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Cleaned, labeled synthetic dataset.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>def generate_framework(\n    self,\n    prompt_path: str = None,\n    prompt_dict_input: dict = None,\n    num_samples: int = 500,\n    json_out: str = None,\n    csv_out: str = None,\n    seed: int = 42,\n    temperature: float = 0.85,\n    top_p: float = 0.90,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Generate a synthetic labeled dataset from prompts using a language model.\n    Either `prompt_path` (path to .py file with `prompt_dict`) or `prompt_dict_input` must be provided.\n\n    Parameters:\n        prompt_path (str): Path to a Python file containing a prompt dictionary.\n        prompt_dict_input (dict): Prompt dictionary directly provided.\n        num_samples (int): Number of samples to generate per category.\n        json_out (str): Optional path to save JSON output.\n        csv_out (str): Optional path to save CSV output.\n        seed (int): Random seed for reproducibility.\n\n    Returns:\n        pd.DataFrame: Cleaned, labeled synthetic dataset.\n    \"\"\"\n    if not prompt_path and not prompt_dict_input:\n        raise ValueError(\n            \"You must provide either a prompt_path or prompt_dict_input.\"\n        )\n\n    set_seed(seed)\n\n    df = synthesize_dataset(\n        prompt_dict=prompt_dict_input,\n        prompt_path=prompt_path,\n        model_name=self.model_name,\n        num_samples=num_samples,\n        api_url=self.api_url,\n        json_out=json_out,\n        csv_out=csv_out,\n        temperature=temperature,\n        top_p=top_p,\n    )\n\n    return df\n</code></pre>"},{"location":"api/api_frame_gen/#educhateval.core.FrameworkGenerator.filter_with_classifier","title":"<code>filter_with_classifier(train_data, synth_data, text_column='text', label_column='category', split_ratio=0.2, training_params=[0.01, 'cross_entropy', 5e-05, 8, 8, 4, 0.01], tuning=False, tuning_params=None, model_save_path=None, classifier_model_name='distilbert-base-uncased', filtered_save_path=None)</code>","text":"<p>Train a small classifier on real labeled data and use it to filter the synthetic dataset by agreement.</p> <p>Parameters:</p> Name Type Description Default <code>train_data</code> <code>str or DataFrame</code> <p>Path or DataFrame of small labeled training set.</p> required <code>synth_data</code> <code>str or DataFrame</code> <p>Path or DataFrame of generated synthetic dataset.</p> required <code>text_column</code> <code>str</code> <p>Name of the text column.</p> <code>'text'</code> <code>label_column</code> <code>str</code> <p>Name of the label column.</p> <code>'category'</code> <code>split_ratio</code> <code>float</code> <p>Ratio for train/test split.</p> <code>0.2</code> <code>training_params</code> <code>list</code> <p>Training hyperparameters.</p> <code>[0.01, 'cross_entropy', 5e-05, 8, 8, 4, 0.01]</code> <code>tuning</code> <code>bool</code> <p>Whether to perform hyperparameter tuning using Optuna.</p> <code>False</code> <code>tuning_params</code> <code>dict</code> <p>Optional tuning grid.</p> <code>None</code> <code>model_save_path</code> <code>str</code> <p>Optional path to save the classifier model.</p> <code>None</code> <code>classifier_model_name</code> <code>str</code> <p>HF model ID for the classifier.</p> <code>'distilbert-base-uncased'</code> <code>filtered_save_path</code> <code>str</code> <p>Optional path to save filtered synthetic dataset.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Filtered synthetic dataset based on classifier agreement.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>def filter_with_classifier(\n    self,\n    train_data: Union[str, pd.DataFrame],\n    synth_data: Union[str, pd.DataFrame],\n    text_column: str = \"text\",\n    label_column: str = \"category\",\n    split_ratio: float = 0.2,\n    training_params: list = [0.01, \"cross_entropy\", 5e-5, 8, 8, 4, 0.01],\n    tuning: bool = False,\n    tuning_params: dict = None,\n    model_save_path: str = None,\n    classifier_model_name: str = \"distilbert-base-uncased\",\n    filtered_save_path: str = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Train a small classifier on real labeled data and use it to filter the synthetic dataset by agreement.\n\n    Parameters:\n        train_data (str or pd.DataFrame): Path or DataFrame of small labeled training set.\n        synth_data (str or pd.DataFrame): Path or DataFrame of generated synthetic dataset.\n        text_column (str): Name of the text column.\n        label_column (str): Name of the label column.\n        split_ratio (float): Ratio for train/test split.\n        training_params (list): Training hyperparameters.\n        tuning (bool): Whether to perform hyperparameter tuning using Optuna.\n        tuning_params (dict): Optional tuning grid.\n        model_save_path (str): Optional path to save the classifier model.\n        classifier_model_name (str): HF model ID for the classifier.\n        filtered_save_path (str): Optional path to save filtered synthetic dataset.\n\n    Returns:\n        pd.DataFrame: Filtered synthetic dataset based on classifier agreement.\n    \"\"\"\n    if isinstance(train_data, pd.DataFrame) and train_data.empty:\n        raise ValueError(\"Provided training DataFrame is empty.\")\n    if isinstance(synth_data, pd.DataFrame) and synth_data.empty:\n        raise ValueError(\"Provided synthetic DataFrame is empty.\")\n\n    tokenizer = load_tokenizer(classifier_model_name)\n\n    dataset_dict, label2id = load_and_prepare_dataset(\n        train_data, text_column, label_column, split_ratio\n    )\n\n    tokenized = tokenize_dataset(dataset_dict, tokenizer)\n\n    model, trainer = train_model(\n        tokenized,\n        classifier_model_name,\n        len(label2id),\n        training_params,\n        tuning,\n        tuning_params,\n    )\n\n    trainer.evaluate()\n\n    if model_save_path:\n        save_model_and_tokenizer(model, tokenizer, model_save_path)\n\n    df_filtered = filter_synthesized_data(\n        synth_input=synth_data,\n        model=model,\n        tokenizer=tokenizer,\n        label_column=label_column,\n        save_path=filtered_save_path,\n    )\n\n    return df_filtered\n</code></pre>"},{"location":"api/api_pred/","title":"Predicting Labels","text":""},{"location":"api/api_pred/#educhateval.core.PredictLabels","title":"<code>educhateval.core.PredictLabels</code>","text":"<p>A wrapper for training and applying a text classification model.</p> <p>This class streamlines the process of fine-tuning a transformer-based classifier on labeled data and applying the trained model to annotate new, unlabeled datasets. Supports both single and multi-column predictions and includes optional model saving and evaluation output.</p> Required Args <p>model_name (str): Name of the pretrained Hugging Face model to fine-tune (default: \"distilbert-base-uncased\").</p> <p>Methods:</p> Name Description <code>run_pipeline</code> <p>Trains the classifier and returns a DataFrame with predicted labels and confidence scores.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>class PredictLabels:\n    \"\"\"\n    A wrapper for training and applying a text classification model.\n\n    This class streamlines the process of fine-tuning a transformer-based classifier on labeled data\n    and applying the trained model to annotate new, unlabeled datasets. Supports both single and multi-column\n    predictions and includes optional model saving and evaluation output.\n\n    Required Args:\n        model_name (str): Name of the pretrained Hugging Face model to fine-tune (default: \"distilbert-base-uncased\").\n\n    Methods:\n        run_pipeline(...): Trains the classifier and returns a DataFrame with predicted labels and confidence scores.\n    \"\"\"\n\n    def __init__(self, model_name: str = \"distilbert-base-uncased\"):\n        self.model_name = model_name\n        self.tokenizer = load_tokenizer(model_name)\n\n    def run_pipeline(\n        self,\n        train_data: Union[str, pd.DataFrame],\n        new_data: Union[str, pd.DataFrame],\n        # columns in the training data\n        text_column: str = \"text\",\n        label_column: str = \"category\",\n        # columns to classify in the new data\n        columns_to_classify: Optional[Union[str, List[str]]] = None,\n        split_ratio: float = 0.2,\n        training_params: list = [0.01, \"cross_entropy\", 5e-5, 8, 8, 4, 0.01],\n        tuning: bool = False,\n        tuning_params: Optional[dict] = None,\n        model_save_path: Optional[str] = None,\n        prediction_save_path: Optional[str] = None,\n        seed: int = 42,\n    ) -&gt; pd.DataFrame:\n\n        # Validate training data input\n        if not isinstance(train_data, (pd.DataFrame, str)):\n            raise ValueError(\n                \"Please provide data training data. This must be a pandas DataFrame or a path to a CSV file.\"\n            )\n\n        if not isinstance(new_data, (pd.DataFrame, str)):\n            raise ValueError(\n                \"Please provide data to be labeled. This must be a pandas DataFrame or a path to a CSV file.\"\n            )\n\n        # Validate training parameters\n        if not isinstance(training_params, list) or len(training_params) &lt; 7:\n            raise ValueError(\n                \"training_params must be a list of at least 7 hyperparameter values.\"\n            )\n\n        if not isinstance(split_ratio, float) or not (0.0 &lt; split_ratio &lt; 1.0):\n            raise ValueError(\"split_ratio must be a float between 0 and 1.\")\n\n        # Validate column names\n        if not isinstance(text_column, str):\n            raise ValueError(\"text_column must be a string.\")\n        if not isinstance(label_column, str):\n            raise ValueError(\"label_column must be a string.\")\n\n        # Validate columns_to_classify\n        if columns_to_classify is not None:\n            if not isinstance(columns_to_classify, (str, list)):\n                raise ValueError(\n                    \"columns_to_classify must be a string or a list of strings.\"\n                )\n            if isinstance(columns_to_classify, list) and not all(\n                isinstance(col, str) for col in columns_to_classify\n            ):\n                raise ValueError(\"All entries in columns_to_classify must be strings.\")\n\n        set_seed(seed)\n\n        dataset_dict, label2id = load_and_prepare_dataset(\n            train_data, text_column, label_column, split_ratio\n        )\n        tokenized = tokenize_dataset(dataset_dict, self.tokenizer)\n\n        model, trainer = train_model(\n            tokenized,\n            self.model_name,\n            len(label2id),\n            training_params,\n            tuning,\n            tuning_params,\n        )\n\n        if model_save_path:\n            save_model_and_tokenizer(model, self.tokenizer, model_save_path)\n\n        # Default to using the training text_column if no specific columns_to_classify provided\n        if columns_to_classify is None:\n            columns_to_classify = text_column\n\n        df_annotated = predict_annotated_dataset(\n            new_data=new_data,\n            model=model,\n            text_columns=columns_to_classify,\n            tokenizer=self.tokenizer,\n            label2id=label2id,\n            save_path=prediction_save_path,\n        )\n\n        return df_annotated\n</code></pre>"},{"location":"api/api_pred/#educhateval.core.PredictLabels.model_name","title":"<code>model_name = model_name</code>  <code>instance-attribute</code>","text":""},{"location":"api/api_pred/#educhateval.core.PredictLabels.tokenizer","title":"<code>tokenizer = load_tokenizer(model_name)</code>  <code>instance-attribute</code>","text":""},{"location":"api/api_pred/#educhateval.core.PredictLabels.__init__","title":"<code>__init__(model_name='distilbert-base-uncased')</code>","text":"Source code in <code>src/educhateval/core.py</code> <pre><code>def __init__(self, model_name: str = \"distilbert-base-uncased\"):\n    self.model_name = model_name\n    self.tokenizer = load_tokenizer(model_name)\n</code></pre>"},{"location":"api/api_pred/#educhateval.core.PredictLabels.run_pipeline","title":"<code>run_pipeline(train_data, new_data, text_column='text', label_column='category', columns_to_classify=None, split_ratio=0.2, training_params=[0.01, 'cross_entropy', 5e-05, 8, 8, 4, 0.01], tuning=False, tuning_params=None, model_save_path=None, prediction_save_path=None, seed=42)</code>","text":"Source code in <code>src/educhateval/core.py</code> <pre><code>def run_pipeline(\n    self,\n    train_data: Union[str, pd.DataFrame],\n    new_data: Union[str, pd.DataFrame],\n    # columns in the training data\n    text_column: str = \"text\",\n    label_column: str = \"category\",\n    # columns to classify in the new data\n    columns_to_classify: Optional[Union[str, List[str]]] = None,\n    split_ratio: float = 0.2,\n    training_params: list = [0.01, \"cross_entropy\", 5e-5, 8, 8, 4, 0.01],\n    tuning: bool = False,\n    tuning_params: Optional[dict] = None,\n    model_save_path: Optional[str] = None,\n    prediction_save_path: Optional[str] = None,\n    seed: int = 42,\n) -&gt; pd.DataFrame:\n\n    # Validate training data input\n    if not isinstance(train_data, (pd.DataFrame, str)):\n        raise ValueError(\n            \"Please provide data training data. This must be a pandas DataFrame or a path to a CSV file.\"\n        )\n\n    if not isinstance(new_data, (pd.DataFrame, str)):\n        raise ValueError(\n            \"Please provide data to be labeled. This must be a pandas DataFrame or a path to a CSV file.\"\n        )\n\n    # Validate training parameters\n    if not isinstance(training_params, list) or len(training_params) &lt; 7:\n        raise ValueError(\n            \"training_params must be a list of at least 7 hyperparameter values.\"\n        )\n\n    if not isinstance(split_ratio, float) or not (0.0 &lt; split_ratio &lt; 1.0):\n        raise ValueError(\"split_ratio must be a float between 0 and 1.\")\n\n    # Validate column names\n    if not isinstance(text_column, str):\n        raise ValueError(\"text_column must be a string.\")\n    if not isinstance(label_column, str):\n        raise ValueError(\"label_column must be a string.\")\n\n    # Validate columns_to_classify\n    if columns_to_classify is not None:\n        if not isinstance(columns_to_classify, (str, list)):\n            raise ValueError(\n                \"columns_to_classify must be a string or a list of strings.\"\n            )\n        if isinstance(columns_to_classify, list) and not all(\n            isinstance(col, str) for col in columns_to_classify\n        ):\n            raise ValueError(\"All entries in columns_to_classify must be strings.\")\n\n    set_seed(seed)\n\n    dataset_dict, label2id = load_and_prepare_dataset(\n        train_data, text_column, label_column, split_ratio\n    )\n    tokenized = tokenize_dataset(dataset_dict, self.tokenizer)\n\n    model, trainer = train_model(\n        tokenized,\n        self.model_name,\n        len(label2id),\n        training_params,\n        tuning,\n        tuning_params,\n    )\n\n    if model_save_path:\n        save_model_and_tokenizer(model, self.tokenizer, model_save_path)\n\n    # Default to using the training text_column if no specific columns_to_classify provided\n    if columns_to_classify is None:\n        columns_to_classify = text_column\n\n    df_annotated = predict_annotated_dataset(\n        new_data=new_data,\n        model=model,\n        text_columns=columns_to_classify,\n        tokenizer=self.tokenizer,\n        label2id=label2id,\n        save_path=prediction_save_path,\n    )\n\n    return df_annotated\n</code></pre>"},{"location":"api/api_synth_int/","title":"Synthesizing Interaction","text":""},{"location":"api/api_synth_int/#educhateval.core.DialogueSimulator","title":"<code>educhateval.core.DialogueSimulator</code>","text":"<p>Module for generating multi-turn dialogues between a student and tutor agent using large language models.</p> <p>This class wraps backend-specific model interfaces and orchestrates the simulation of goal-driven conversations across various educational modes. It supports customizable sampling behavior and ensures reproducibility via global seeding. Outputs are returned as structured pandas DataFrames.</p> <p>Attributes:</p> Name Type Description <code>backend</code> <code>str</code> <p>Backend to use for inference. Options are \"hf\" (Hugging Face) or \"mlx\" (MLX).</p> <code>model_id</code> <code>str</code> <p>The identifier of the model to use, e.g., \"gpt2\" (Hugging Face) or \"Qwen2.5-7B-Instruct-1M-4bit\" (MLX).</p> <code>sampling_params</code> <code>Optional[dict]</code> <p>Sampling hyperparameters such as temperature, top_p, or top_k.</p> <p>Methods:</p> Name Description <code>simulate_dialogue</code> <p>Simulates a dialogue and returns it as a pandas DataFrame.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>class DialogueSimulator:\n    \"\"\"\n    Module for generating multi-turn dialogues between a student and tutor agent using large language models.\n\n    This class wraps backend-specific model interfaces and orchestrates the simulation of goal-driven conversations across various educational modes.\n    It supports customizable sampling behavior and ensures reproducibility via global seeding. Outputs are returned as structured pandas DataFrames.\n\n    Attributes:\n        backend (str): Backend to use for inference. Options are \"hf\" (Hugging Face) or \"mlx\" (MLX).\n        model_id (str): The identifier of the model to use, e.g., \"gpt2\" (Hugging Face) or \"Qwen2.5-7B-Instruct-1M-4bit\" (MLX).\n        sampling_params (Optional[dict]): Sampling hyperparameters such as temperature, top_p, or top_k.\n\n    Methods:\n        simulate_dialogue(...): Simulates a dialogue and returns it as a pandas DataFrame.\n    \"\"\"\n\n    def __init__(\n        self,\n        backend: str = \"mlx\",\n        model_id: str = \"mlx-community/Qwen2.5-7B-Instruct-1M-4bit\",\n        sampling_params: Optional[dict] = None,\n    ):\n        if backend == \"hf\":\n            self.model = ChatHF(\n                model_id=model_id,\n                sampling_params=sampling_params\n                or {\"temperature\": 0.9, \"top_p\": 0.9, \"top_k\": 50},\n            )\n        elif backend == \"mlx\":\n            self.model = ChatMLX(\n                model_id=model_id,\n                sampling_params=sampling_params\n                or {\"temp\": 0.9, \"top_p\": 0.9, \"top_k\": 40},\n            )\n        else:\n            raise ValueError(\"Unsupported backend\")\n\n        self.model.load()\n\n    def simulate_dialogue(\n        self,\n        mode: str = \"general_task_solving\",\n        turns: int = 5,\n        seed_message_input: str = \"Hi, I'm a student seeking assistance with my studies.\",\n        log_dir: Optional[Path] = None,\n        save_csv_path: Optional[Path] = None,\n        seed: int = 42,\n        custom_prompt_file: Optional[Path] = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Simulates a multi-turn dialogue using either built-in or custom prompts.\n\n        Args:\n            mode: Mode key to select prompt pair (student/tutor).\n            turns: Number of back-and-forth turns to simulate.\n            seed_message_input: First message from the student.\n            log_dir: Directory to save raw log (optional).\n            save_csv_path: Path to save structured DataFrame (optional).\n            seed: Random seed for reproducibility.\n            custom_prompt_file: Optional path to custom YAML defining prompt modes.\n\n        Returns:\n            pd.DataFrame: Structured DataFrame of the conversation.\n        \"\"\"\n        set_seed(seed)\n\n        # system_prompts = load_prompts_and_seed(mode)\n\n        df = simulate_conversation(\n            model=self.model,\n            turns=turns,\n            seed_message_input=seed_message_input,\n            log_dir=log_dir,\n            save_csv_path=save_csv_path,\n            custom_prompt_file=custom_prompt_file,\n            mode=mode,\n        )\n\n        print(\n            f\"\\n Full dialogue stored in DataFrame: use the returned object or view as `df`\"\n        )\n        return df\n</code></pre>"},{"location":"api/api_synth_int/#educhateval.core.DialogueSimulator.model","title":"<code>model = ChatHF(model_id=model_id, sampling_params=sampling_params or {'temperature': 0.9, 'top_p': 0.9, 'top_k': 50})</code>  <code>instance-attribute</code>","text":""},{"location":"api/api_synth_int/#educhateval.core.DialogueSimulator.__init__","title":"<code>__init__(backend='mlx', model_id='mlx-community/Qwen2.5-7B-Instruct-1M-4bit', sampling_params=None)</code>","text":"Source code in <code>src/educhateval/core.py</code> <pre><code>def __init__(\n    self,\n    backend: str = \"mlx\",\n    model_id: str = \"mlx-community/Qwen2.5-7B-Instruct-1M-4bit\",\n    sampling_params: Optional[dict] = None,\n):\n    if backend == \"hf\":\n        self.model = ChatHF(\n            model_id=model_id,\n            sampling_params=sampling_params\n            or {\"temperature\": 0.9, \"top_p\": 0.9, \"top_k\": 50},\n        )\n    elif backend == \"mlx\":\n        self.model = ChatMLX(\n            model_id=model_id,\n            sampling_params=sampling_params\n            or {\"temp\": 0.9, \"top_p\": 0.9, \"top_k\": 40},\n        )\n    else:\n        raise ValueError(\"Unsupported backend\")\n\n    self.model.load()\n</code></pre>"},{"location":"api/api_synth_int/#educhateval.core.DialogueSimulator.simulate_dialogue","title":"<code>simulate_dialogue(mode='general_task_solving', turns=5, seed_message_input=\"Hi, I'm a student seeking assistance with my studies.\", log_dir=None, save_csv_path=None, seed=42, custom_prompt_file=None)</code>","text":"<p>Simulates a multi-turn dialogue using either built-in or custom prompts.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>Mode key to select prompt pair (student/tutor).</p> <code>'general_task_solving'</code> <code>turns</code> <code>int</code> <p>Number of back-and-forth turns to simulate.</p> <code>5</code> <code>seed_message_input</code> <code>str</code> <p>First message from the student.</p> <code>\"Hi, I'm a student seeking assistance with my studies.\"</code> <code>log_dir</code> <code>Optional[Path]</code> <p>Directory to save raw log (optional).</p> <code>None</code> <code>save_csv_path</code> <code>Optional[Path]</code> <p>Path to save structured DataFrame (optional).</p> <code>None</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>42</code> <code>custom_prompt_file</code> <code>Optional[Path]</code> <p>Optional path to custom YAML defining prompt modes.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Structured DataFrame of the conversation.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>def simulate_dialogue(\n    self,\n    mode: str = \"general_task_solving\",\n    turns: int = 5,\n    seed_message_input: str = \"Hi, I'm a student seeking assistance with my studies.\",\n    log_dir: Optional[Path] = None,\n    save_csv_path: Optional[Path] = None,\n    seed: int = 42,\n    custom_prompt_file: Optional[Path] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Simulates a multi-turn dialogue using either built-in or custom prompts.\n\n    Args:\n        mode: Mode key to select prompt pair (student/tutor).\n        turns: Number of back-and-forth turns to simulate.\n        seed_message_input: First message from the student.\n        log_dir: Directory to save raw log (optional).\n        save_csv_path: Path to save structured DataFrame (optional).\n        seed: Random seed for reproducibility.\n        custom_prompt_file: Optional path to custom YAML defining prompt modes.\n\n    Returns:\n        pd.DataFrame: Structured DataFrame of the conversation.\n    \"\"\"\n    set_seed(seed)\n\n    # system_prompts = load_prompts_and_seed(mode)\n\n    df = simulate_conversation(\n        model=self.model,\n        turns=turns,\n        seed_message_input=seed_message_input,\n        log_dir=log_dir,\n        save_csv_path=save_csv_path,\n        custom_prompt_file=custom_prompt_file,\n        mode=mode,\n    )\n\n    print(\n        f\"\\n Full dialogue stored in DataFrame: use the returned object or view as `df`\"\n    )\n    return df\n</code></pre>"},{"location":"api/api_viz/","title":"Visualizer","text":"<p>This class can be used to generate four different visualizations to analysis the interactions by.  Every visualization besides the Interaction Distribution plot can be created for either the student, the tutor or both. The Interaction Distribution plot needs both student and tutor data to visualize interactions. </p>"},{"location":"api/api_viz/#1-barchart-of-predicted-classes","title":"1. Barchart of Predicted Classes","text":"<p>Example usage: </p> <pre><code>viz.plot_category_bars(\n    df=annotated_df,\n    student_col=\"predicted_labels_student_msg\",\n    tutor_col=\"predicted_labels_tutor_msg\",\n    use_percent=True,\n    title=\"Distribution of Predicted Classes\"\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> The input DataFrame containing predicted categories for student and/or tutor. required <code>student_col</code> <code>str</code> or <code>None</code> Name of the column with student-predicted labels. Optional. <code>None</code> <code>tutor_col</code> <code>str</code> or <code>None</code> Name of the column with tutor-predicted labels. Optional. <code>None</code> <code>palette</code> <code>str</code> Color palette used for the plot. Optional. <code>\"icefire\"</code> <code>title</code> <code>str</code> Title of the plot. Optional. <code>\"Predicted Classes\"</code> <p>Returns:</p> Name Type Description \u2014 <code>None</code> Displays the plot using <code>matplotlib.pyplot.show()</code>. No object is returned."},{"location":"api/api_viz/#educhateval.descriptive_results.display_results.plot_category_bars","title":"<code>educhateval.descriptive_results.display_results.plot_category_bars(df, student_col=None, tutor_col=None, use_percent=True, palette='icefire', title='Predicted Classes')</code>","text":"Source code in <code>src/educhateval/descriptive_results/display_results.py</code> <pre><code>def plot_category_bars(\n    df,\n    student_col=None,\n    tutor_col=None,\n    use_percent=True,\n    palette=\"icefire\",\n    title=\"Predicted Classes\",\n):\n    if not student_col and not tutor_col:\n        raise ValueError(\"You must provide at least one of student_col or tutor_col.\")\n\n    long_dfs = []\n    if student_col:\n        temp = df[[student_col]].copy()\n        temp[\"source\"] = \"Student\"\n        temp.rename(columns={student_col: \"predicted_label\"}, inplace=True)\n        long_dfs.append(temp)\n    if tutor_col:\n        temp = df[[tutor_col]].copy()\n        temp[\"source\"] = \"Tutor\"\n        temp.rename(columns={tutor_col: \"predicted_label\"}, inplace=True)\n        long_dfs.append(temp)\n\n    long_df = pd.concat(long_dfs, ignore_index=True)\n\n    all_labels = sorted(long_df[\"predicted_label\"].dropna().unique())\n    long_df[\"predicted_label\"] = pd.Categorical(\n        long_df[\"predicted_label\"], categories=all_labels, ordered=True\n    )\n\n    count_df = (\n        long_df.groupby([\"source\", \"predicted_label\"], observed=True)\n        .size()\n        .reset_index(name=\"count\")\n    )\n\n    if use_percent:\n        total_per_source = count_df.groupby(\"source\", observed=True)[\"count\"].transform(\n            \"sum\"\n        )\n        count_df[\"value\"] = (count_df[\"count\"] / total_per_source) * 100\n        y_label = \"Occurrences (%)\"\n        fmt = lambda val: f\"{val:.0f}%\"\n    else:\n        count_df[\"value\"] = count_df[\"count\"]\n        y_label = \"Number of Occurrences\"\n        fmt = lambda val: f\"{int(val)}\"\n\n    sns.set_style(\"whitegrid\")\n    plt.figure(figsize=(10, 6))\n\n    ax = sns.barplot(\n        data=count_df,\n        x=\"predicted_label\",\n        y=\"value\",\n        hue=\"source\",\n        palette=palette,\n        order=all_labels,\n    )\n\n    ax.set_xlabel(\"Predicted Category\")\n    ax.set_ylabel(y_label)\n    ax.set_title(title, fontsize=15, fontweight=\"bold\")\n\n    if use_percent:\n        ax.yaxis.set_major_formatter(mtick.FuncFormatter(lambda y, _: f\"{y:.0f}%\"))\n\n    for container in ax.containers:\n        for bar in container:\n            height = bar.get_height()\n            if height &gt; 0:\n                ax.annotate(\n                    fmt(height),\n                    xy=(bar.get_x() + bar.get_width() / 2, height),\n                    xytext=(0, 3),\n                    textcoords=\"offset points\",\n                    ha=\"center\",\n                    va=\"bottom\",\n                    fontsize=9,\n                )\n\n    plt.legend(title=\"Agent\")\n    plt.tight_layout()\n    plt.show()\n</code></pre>"},{"location":"api/api_viz/#2-summary-table","title":"2. Summary Table","text":"<p>Example usage: </p> <pre><code>summary = viz.create_summary_table(\n    df=annotated_df,\n    student_col=\"predicted_labels_student_msg\",\n    tutor_col=\"predicted_labels_tutor_msg\"\n)\n\nprint(summary)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> The input DataFrame containing predicted categories for student and/or tutor. required <code>student_col</code> <code>str</code> or <code>None</code> Name of the column with student-predicted labels. Optional. <code>None</code> <code>tutor_col</code> <code>str</code> or <code>None</code> Name of the column with tutor-predicted labels. Optional. <code>None</code> <p>Returns:</p> Name Type Description <code>summary_df</code> <code>DataFrame</code> A summary table with counts and percentages for each predicted category. Splits by student and tutor (if provided). Missing values are filled with 0."},{"location":"api/api_viz/#educhateval.descriptive_results.display_results.create_prediction_summary_table","title":"<code>educhateval.descriptive_results.display_results.create_prediction_summary_table(df, student_col=None, tutor_col=None)</code>","text":"Source code in <code>src/educhateval/descriptive_results/display_results.py</code> <pre><code>def create_prediction_summary_table(df, student_col=None, tutor_col=None):\n    if not student_col and not tutor_col:\n        raise ValueError(\"You must provide at least one of student_col or tutor_col.\")\n\n    result_dfs = []\n    all_categories = set()\n\n    if student_col:\n        student_counts = df[student_col].value_counts(dropna=False)\n        total = student_counts.sum()\n        counts = student_counts.rename(\"Student (n)\")\n        percents = ((student_counts / total) * 100).round(1).astype(str) + \"%\"\n        percents.name = \"Student (%)\"\n        merged = pd.concat([counts, percents], axis=1)\n        result_dfs.append(merged)\n        all_categories.update(merged.index)\n\n    if tutor_col:\n        tutor_counts = df[tutor_col].value_counts(dropna=False)\n        total = tutor_counts.sum()\n        counts = tutor_counts.rename(\"Tutor (n)\")\n        percents = ((tutor_counts / total) * 100).round(1).astype(str) + \"%\"\n        percents.name = \"Tutor (%)\"\n        merged = pd.concat([counts, percents], axis=1)\n        result_dfs.append(merged)\n        all_categories.update(merged.index)\n\n    full_index = pd.Index(sorted(all_categories), name=\"Predicted Category\")\n    summary_df = pd.DataFrame(index=full_index)\n\n    for df_part in result_dfs:\n        summary_df = summary_df.join(df_part, how=\"left\")\n\n    for col in summary_df.columns:\n        if \"(n)\" in col:\n            summary_df[col] = summary_df[col].fillna(0).astype(int)\n        elif \"(%)\" in col:\n            summary_df[col] = summary_df[col].fillna(\"0.0%\")\n\n    summary_df = summary_df.reset_index()\n    return summary_df\n</code></pre>"},{"location":"api/api_viz/#3-predicted-classes-by-turns","title":"3. Predicted Classes by Turns","text":"<p>Example usage: </p> <pre><code>plot_predicted_categories(\n        df=annotated_df,\n        student_col=\"predicted_labels_student_msg\",\n        tutor_col=\"predicted_labels_tutor_msg\",\n        title=\"Predicted Category Distribution\"\n    )\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> Input DataFrame with turn-level predicted labels for student and/or tutor. required <code>student_col</code> <code>str</code> or <code>None</code> Name of the column containing student-predicted categories. Optional. <code>None</code> <code>tutor_col</code> <code>str</code> or <code>None</code> Name of the column containing tutor-predicted categories. Optional. <code>None</code> <code>use_percent</code> <code>bool</code> Whether to plot percentage values (<code>True</code>) or raw counts (<code>False</code>). <code>True</code> <code>palette</code> <code>str</code> Color palette used for the plot. Optional. <code>\"icefire\"</code> <code>title</code> <code>str</code> Title of the plot. Optional. <code>\"Predicted Classes\"</code> <p>Returns:</p> Name Type Description \u2014 <code>None</code> Displays the plot using <code>matplotlib.pyplot.show()</code>. No object is returned."},{"location":"api/api_viz/#educhateval.descriptive_results.display_results.plot_predicted_categories","title":"<code>educhateval.descriptive_results.display_results.plot_predicted_categories(df, student_col=None, tutor_col=None, use_percent=True, palette='icefire', title='Predicted Category Distribution')</code>","text":"Source code in <code>src/educhateval/descriptive_results/display_results.py</code> <pre><code>def plot_predicted_categories(\n    df,\n    student_col=None,\n    tutor_col=None,\n    use_percent=True,\n    palette=\"icefire\",\n    title=\"Predicted Category Distribution\",\n):\n    if not student_col and not tutor_col:\n        raise ValueError(\"You must provide at least one of student_col or tutor_col.\")\n\n    # Prepare long format\n    long_dfs = []\n    if student_col:\n        temp = df[[\"turn\", student_col]].copy()\n        temp[\"source\"] = \"Student\"\n        temp.rename(columns={student_col: \"predicted_label\"}, inplace=True)\n        long_dfs.append(temp)\n    if tutor_col:\n        temp = df[[\"turn\", tutor_col]].copy()\n        temp[\"source\"] = \"Tutor\"\n        temp.rename(columns={tutor_col: \"predicted_label\"}, inplace=True)\n        long_dfs.append(temp)\n\n    long_df = pd.concat(long_dfs, ignore_index=True)\n\n    all_labels = sorted(long_df[\"predicted_label\"].dropna().unique())\n    long_df[\"predicted_label\"] = pd.Categorical(\n        long_df[\"predicted_label\"], categories=all_labels, ordered=True\n    )\n\n    count_df = (\n        long_df.groupby([\"turn\", \"source\", \"predicted_label\"], observed=True)\n        .size()\n        .reset_index(name=\"count\")\n    )\n\n    if use_percent:\n        total_per_group = count_df.groupby([\"turn\", \"source\"], observed=True)[\n            \"count\"\n        ].transform(\"sum\")\n        count_df[\"value\"] = (count_df[\"count\"] / total_per_group) * 100\n        y_label = \"Occurrences (%)\"\n        fmt = lambda y, _: f\"{y:.0f}%\"\n        y_max = 100\n    else:\n        count_df[\"value\"] = count_df[\"count\"]\n        y_label = \"Number of Occurrences\"\n        fmt = lambda y, _: f\"{int(y)}\"\n        y_max = count_df[\"value\"].max() + 3\n\n    sns.set_style(\"whitegrid\")\n    g = sns.relplot(\n        data=count_df,\n        x=\"turn\",\n        y=\"value\",\n        hue=\"predicted_label\",\n        kind=\"line\",\n        col=\"source\" if student_col and tutor_col else None,\n        facet_kws={\"sharey\": True, \"sharex\": True},\n        height=4.5,\n        aspect=1.5,\n        marker=\"o\",\n        palette=palette,\n        hue_order=all_labels,\n    )\n\n    if student_col and tutor_col:\n        g.set_titles(\"{col_name} Messages\")\n    g.set_axis_labels(\"Turn\", y_label)\n\n    g.fig.subplots_adjust(right=0.85)\n    g._legend.set_bbox_to_anchor((1.12, 0.5))\n    g._legend.set_frame_on(True)\n    g._legend.set_title(\"Predicted Category\")\n\n    for ax in g.axes.flat:\n        ax.set_ylim(0, y_max)\n        ax.yaxis.set_major_formatter(mtick.FuncFormatter(fmt))\n\n    plt.suptitle(title, fontsize=15, fontweight=\"bold\", y=0.95)\n    plt.tight_layout()\n    plt.show()\n</code></pre>"},{"location":"api/api_viz/#4-interaction-distribution","title":"4. Interaction Distribution","text":"<p>Example usage:</p> <pre><code>viz.plot_history_interaction(\n    df=annotated_df,\n    student_col=\"predicted_labels_student_msg\",\n    tutor_col=\"predicted_labels_tutor_msg\",\n    focus_agent=\"tutor\",\n    use_percent=True\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> Input DataFrame including turn-level predicted labels for both student and tutor. required <code>student_col</code> <code>str</code> or <code>None</code> Column name containing student-predicted categories. required <code>tutor_col</code> <code>str</code> or <code>None</code> Column name containing tutor-predicted categories. required <code>focus_agent</code> <code>str</code> Determines whether to analyze the student or tutor perspective. Options: \"student\" or \"tutor\". <code>\"student\"</code> <code>use_percent</code> <code>bool</code> If <code>True</code>, the y-axis will display percentages; otherwise raw counts are shown. <code>True</code> <code>palette</code> <code>str</code> Color palette used for the plot. Optional. <code>\"icefire\"</code> <p>Returns:</p> Name Type Description \u2014 <code>None</code> Displays the plot using <code>matplotlib.pyplot.show()</code>. No object is returned."},{"location":"api/api_viz/#educhateval.descriptive_results.display_results.plot_previous_turn_distribution","title":"<code>educhateval.descriptive_results.display_results.plot_previous_turn_distribution(df, student_col='predicted_labels_student_msg', tutor_col='predicted_labels_tutor_msg', focus_agent='student', use_percent=True, palette='icefire')</code>","text":"<p>Plot the distribution of predicted categories in the previous turn of the opposite agent. Both student and tutor is required.</p> Source code in <code>src/educhateval/descriptive_results/display_results.py</code> <pre><code>def plot_previous_turn_distribution(\n    df, \n    student_col=\"predicted_labels_student_msg\", \n    tutor_col=\"predicted_labels_tutor_msg\", \n    focus_agent=\"student\", \n    use_percent=True,\n    palette=\"icefire\"\n):\n    \"\"\"\n    Plot the distribution of predicted categories in the previous turn of the *opposite* agent. Both student and tutor is required.\n    \"\"\"\n\n    if not student_col or not tutor_col:\n        raise ValueError(\n                \"Both student_col and tutor_col must be provided.\"\n            )\n\n    if focus_agent not in [\"student\", \"tutor\"]:\n        raise ValueError(\"focus_agent must be either 'student' or 'tutor'.\")\n\n    if focus_agent == \"student\":\n        if not student_col or not tutor_col:\n            raise ValueError(\n                \"Both student_col and tutor_col must be provided when focus_agent='student'.\"\n            )\n        focus_col = student_col\n        opposite_col = tutor_col\n        focus_label = \"Student\"\n        opposite_label = \"Tutor\"\n    else:\n        if not student_col or not tutor_col:\n            raise ValueError(\n                \"Both student_col and tutor_col must be provided when focus_agent='tutor'.\"\n            )\n        focus_col = tutor_col\n        opposite_col = student_col\n        focus_label = \"Tutor\"\n        opposite_label = \"Student\"\n\n    # Prepare shifted column\n    df_sorted = df.sort_values(by=[\"student_id\", \"turn\"]).copy()\n    df_sorted[\"prev_opposite_label\"] = df_sorted.groupby(\"student_id\")[\n        opposite_col\n    ].shift(1)\n    df_filtered = df_sorted.dropna(subset=[focus_col, \"prev_opposite_label\"])\n\n    # Count combinations\n    grouped = (\n        df_filtered.groupby([focus_col, \"prev_opposite_label\"], observed=True)\n        .size()\n        .reset_index(name=\"count\")\n    )\n\n    if use_percent:\n        total_per_focus = grouped.groupby(focus_col, observed=True)[\"count\"].transform(\n            \"sum\"\n        )\n        grouped[\"percentage\"] = (grouped[\"count\"] / total_per_focus) * 100\n        y_col = \"percentage\"\n        y_label = f\"Category in Previous Turn for {opposite_label} (%)\"\n        fmt = lambda val: f\"{val:.0f}%\"\n    else:\n        grouped[\"percentage\"] = grouped[\"count\"]\n        y_col = \"count\"\n        y_label = f\"Category in Previous Turn for {opposite_label} (n)\"\n        fmt = lambda val: f\"{int(val)}\"\n\n    # Ensure all category combinations are represented\n    focus_vals = sorted(df_filtered[focus_col].dropna().unique())\n    prev_vals = sorted(df_filtered[\"prev_opposite_label\"].dropna().unique())\n    full_grid = pd.MultiIndex.from_product(\n        [focus_vals, prev_vals], names=[focus_col, \"prev_opposite_label\"]\n    ).to_frame(index=False)\n    grouped = full_grid.merge(\n        grouped, on=[focus_col, \"prev_opposite_label\"], how=\"left\"\n    ).fillna(0)\n    grouped[\"count\"] = grouped[\"count\"].astype(int)\n    if use_percent:\n        grouped[\"percentage\"] = (\n            grouped.groupby(focus_col)[\"count\"]\n            .transform(lambda x: x / x.sum() * 100)\n            .fillna(0)\n        )\n\n    grouped = grouped.sort_values(by=[focus_col, \"prev_opposite_label\"])\n\n    # Plot\n    sns.set_style(\"whitegrid\")\n    g = sns.catplot(\n        data=grouped,\n        x=focus_col,\n        y=y_col,\n        hue=\"prev_opposite_label\",\n        kind=\"bar\",\n        palette=palette,\n        height=6,\n        aspect=2.5,\n        dodge=True,\n        order=focus_vals,\n        hue_order=prev_vals,\n    )\n\n    # Adjust bar width\n    for patch in g.ax.patches:\n        patch.set_width(patch.get_width() * 0.9)\n\n    # Labels and title\n    g.set_axis_labels(f\"Category in Current Turn for {focus_label}\", y_label)\n    g.fig.suptitle(\n        f\"Distribution of Interactions: {focus_label} Focus\",\n        fontsize=15,\n        fontweight=\"bold\",\n        y=0.99,\n    )\n\n    if use_percent:\n        g.ax.set_ylim(0, 100)\n        g.ax.yaxis.set_major_formatter(mtick.FuncFormatter(lambda y, _: f\"{y:.0f}%\"))\n\n    # Annotate values (including 0s)\n    dodge_width = 0.8 / len(prev_vals)\n    for i, row in grouped.iterrows():\n        x_pos = focus_vals.index(row[focus_col])\n        hue_idx = prev_vals.index(row[\"prev_opposite_label\"])\n        xpos_shifted = x_pos - 0.4 + dodge_width / 2 + hue_idx * dodge_width\n        height = row[y_col]\n        g.ax.annotate(\n            fmt(height),\n            xy=(xpos_shifted, height),\n            xytext=(0, 3),\n            textcoords=\"offset points\",\n            ha=\"center\",\n            va=\"bottom\",\n            fontsize=9,\n        )\n\n    g.fig.subplots_adjust(right=0.85)\n    g._legend.set_bbox_to_anchor((1.12, 0.5))\n    g._legend.set_frame_on(True)\n    g._legend.set_title(f\"{opposite_label} Category (Turn - 1)\")\n\n    plt.tight_layout()\n    plt.show()\n</code></pre>"},{"location":"api/api_wrap_int/","title":"Wrap Interaction","text":""},{"location":"api/api_wrap_int/#this-one-you-need-to-do-on-your-own-kind-of-like-the-tutorial","title":"THIS ONE YOU NEED TO DO ON YOUR OWN KIND OF LIKE THE TUTORIAL !!!!!!!!!","text":""}]}