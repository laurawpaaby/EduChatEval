{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Lauras Python Package","text":"<p>If your interested in evaluating the usage of bots in education yay </p>"},{"location":"about/","title":"About","text":""},{"location":"about/#project","title":"Project","text":"<p>This package was developed as part of a master\u2019s thesis on the MSc in Cognitive Science at Aarhus University. With this package, I hope to contribute to the development of methods for evaluating the use of LLMs.</p> <p>The main contribution is refining and wrapping existing methods into a coherent test suite. Additionally, we have introduced our own evaluation and visualization functions to present the results of various metrics in a cohesive manner.</p>"},{"location":"about/#contact","title":"Contact","text":"<p>If you have any questions regarding the project or the code implementation, feel free to contact someone@example.com.</p> <p>Chatwrap is licensed under MIT and available on GitHub.</p>"},{"location":"about/#acknowledgements","title":"Acknowledgements","text":"<p>This project uses code from three already implemented frameworks for quantifying gender bias in Danish. While all externally authored code is properly attributed in the repository\u2019s scripts, we would also like to acknowledge the authors of the work we draw on:</p> <p>Reference 1: Author, A. A. (Year). Title of the article. Journal Title, 10(2), 123\u2013145. https://doi.org/10.0000/xyz123 Reference 2: Author, B. B., &amp; Author, C. C. (Year). Another work. Publisher. https://doi.org/10.0000/abc456 Reference 3: Author, D. D. (Year). Yet another reference. Conference Proceedings. https://doi.org/10.0000/def789 Reference 4: Organization E. (Year). Document title. Retrieved from https://doi.org/10.0000/ghi012</p>"},{"location":"installation/","title":"Installation","text":"<p>You can install chat wrappy using via pip from PyPI:</p> <p><code>pip install chat-wrappy</code></p> <p>Or from Github:</p> <p><code>pip install git+https://github.com/laurawpaaby/EduChatEval.git</code></p>"},{"location":"api/api_frame_gen/","title":"Framework Generator","text":"<p>This is a test displaying: </p> <p>High-level interface for generating synthetic datasets (frameworks) using prompts and local LLMs.</p> <p>Includes: - Synthetic data generation using instruction-tuned models. - Filtering of low-quality examples via classifier agreement with a small labeled dataset.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>class FrameworkGenerator:\n    \"\"\"\n    High-level interface for generating synthetic datasets (frameworks) using prompts and local LLMs.\n\n    Includes:\n    - Synthetic data generation using instruction-tuned models.\n    - Filtering of low-quality examples via classifier agreement with a small labeled dataset.\n    \"\"\"\n\n    def __init__(\n        self,\n        model_name: str = \"llama-3.2-3b-instruct\",\n        api_url: str = \"http://localhost:1234/v1/completions\",\n    ):\n        \"\"\"\n        Initialize the framework generator.\n\n        Parameters:\n        - model_name (str): Name of the generative model to use (e.g., llama-3.2-3b-instruct).\n        - api_url (str): URL endpoint to communicate with the locally hosted LLM (e.g., LM Studio).\n        \"\"\"\n        self.model_name = model_name\n        self.api_url = api_url\n\n    def generate_framework(\n        self,\n        prompt_path: str = None,\n        prompt_dict_input: dict = None,\n        num_samples: int = 500,\n        json_out: str = None,\n        csv_out: str = None,\n        seed: int = 42,\n        temperature: float = 0.85,\n        top_p: float = 0.90,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Generate a synthetic labeled dataset from prompts using a language model.\n\n        Either `prompt_path` (path to .py file with `prompt_dict`) or `prompt_dict_input` must be provided.\n\n        Parameters:\n        - prompt_path (str): Path to a Python file containing a prompt dictionary.\n        - prompt_dict_input (dict): Prompt dictionary directly provided.\n        - num_samples (int): Number of samples to generate per category.\n        - json_out (str): Optional path to save JSON output.\n        - csv_out (str): Optional path to save CSV output.\n        - seed (int): Random seed for reproducibility.\n\n        Returns:\n        - pd.DataFrame: Cleaned, labeled synthetic dataset.\n        \"\"\"\n        if not prompt_path and not prompt_dict_input:\n            raise ValueError(\n                \"You must provide either a prompt_path or prompt_dict_input.\"\n            )\n\n        set_seed(seed)\n\n        df = synthesize_dataset(\n            prompt_dict=prompt_dict_input,\n            prompt_path=prompt_path,\n            model_name=self.model_name,\n            num_samples=num_samples,\n            api_url=self.api_url,\n            json_out=json_out,\n            csv_out=csv_out,\n            temperature=temperature,\n            top_p=top_p,\n        )\n\n        return df\n\n    #### 2. function to quality check the dataset\n    def filter_with_classifier(\n        self,\n        train_data: Union[str, pd.DataFrame],\n        synth_data: Union[str, pd.DataFrame],\n        text_column: str = \"text\",\n        label_column: str = \"category\",\n        split_ratio: float = 0.2,\n        training_params: list = [0.01, \"cross_entropy\", 5e-5, 8, 8, 4, 0.01],\n        tuning: bool = False,\n        tuning_params: dict = None,\n        model_save_path: str = None,\n        classifier_model_name: str = \"distilbert-base-uncased\",\n        filtered_save_path: str = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Train a small classifier on real labeled data and use it to filter the synthetic dataset by agreement.\n\n        Parameters:\n        - train_data (str or pd.DataFrame): Path or DataFrame of small labeled training set.\n        - synth_data (str or pd.DataFrame): Path or DataFrame of generated synthetic dataset.\n        - text_column (str): Name of the text column.\n        - label_column (str): Name of the label column.\n        - split_ratio (float): Ratio for train/test split.\n        - training_params (list): Training hyperparameters.\n        - tuning (bool): Whether to perform hyperparameter tuning using Optuna.\n        - tuning_params (dict): Optional tuning grid.\n        - model_save_path (str): Optional path to save the classifier model.\n        - classifier_model_name (str): HF model ID for the classifier.\n        - filtered_save_path (str): Optional path to save filtered synthetic dataset.\n\n        Returns:\n        - pd.DataFrame: Filtered synthetic dataset based on classifier agreement.\n        \"\"\"\n        if isinstance(train_data, pd.DataFrame) and train_data.empty:\n            raise ValueError(\"Provided training DataFrame is empty.\")\n        if isinstance(synth_data, pd.DataFrame) and synth_data.empty:\n            raise ValueError(\"Provided synthetic DataFrame is empty.\")\n\n        tokenizer = load_tokenizer(classifier_model_name)\n\n        dataset_dict, label2id = load_and_prepare_dataset(\n            train_data, text_column, label_column, split_ratio\n        )\n\n        tokenized = tokenize_dataset(dataset_dict, tokenizer)\n\n        model, trainer = train_model(\n            tokenized,\n            classifier_model_name,\n            len(label2id),\n            training_params,\n            tuning,\n            tuning_params,\n        )\n\n        trainer.evaluate()\n\n        if model_save_path:\n            save_model_and_tokenizer(model, tokenizer, model_save_path)\n\n        df_filtered = filter_synthesized_data(\n            synth_input=synth_data,\n            model=model,\n            tokenizer=tokenizer,\n            label_column=label_column,\n            save_path=filtered_save_path,\n        )\n\n        return df_filtered\n</code></pre>"},{"location":"api/api_frame_gen/#educhateval.core.FrameworkGenerator.__init__","title":"<code>__init__(model_name='llama-3.2-3b-instruct', api_url='http://localhost:1234/v1/completions')</code>","text":"<p>Initialize the framework generator.</p> <p>Parameters: - model_name (str): Name of the generative model to use (e.g., llama-3.2-3b-instruct). - api_url (str): URL endpoint to communicate with the locally hosted LLM (e.g., LM Studio).</p> Source code in <code>src/educhateval/core.py</code> <pre><code>def __init__(\n    self,\n    model_name: str = \"llama-3.2-3b-instruct\",\n    api_url: str = \"http://localhost:1234/v1/completions\",\n):\n    \"\"\"\n    Initialize the framework generator.\n\n    Parameters:\n    - model_name (str): Name of the generative model to use (e.g., llama-3.2-3b-instruct).\n    - api_url (str): URL endpoint to communicate with the locally hosted LLM (e.g., LM Studio).\n    \"\"\"\n    self.model_name = model_name\n    self.api_url = api_url\n</code></pre>"},{"location":"api/api_frame_gen/#educhateval.core.FrameworkGenerator.filter_with_classifier","title":"<code>filter_with_classifier(train_data, synth_data, text_column='text', label_column='category', split_ratio=0.2, training_params=[0.01, 'cross_entropy', 5e-05, 8, 8, 4, 0.01], tuning=False, tuning_params=None, model_save_path=None, classifier_model_name='distilbert-base-uncased', filtered_save_path=None)</code>","text":"<p>Train a small classifier on real labeled data and use it to filter the synthetic dataset by agreement.</p> <p>Parameters: - train_data (str or pd.DataFrame): Path or DataFrame of small labeled training set. - synth_data (str or pd.DataFrame): Path or DataFrame of generated synthetic dataset. - text_column (str): Name of the text column. - label_column (str): Name of the label column. - split_ratio (float): Ratio for train/test split. - training_params (list): Training hyperparameters. - tuning (bool): Whether to perform hyperparameter tuning using Optuna. - tuning_params (dict): Optional tuning grid. - model_save_path (str): Optional path to save the classifier model. - classifier_model_name (str): HF model ID for the classifier. - filtered_save_path (str): Optional path to save filtered synthetic dataset.</p> <p>Returns: - pd.DataFrame: Filtered synthetic dataset based on classifier agreement.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>def filter_with_classifier(\n    self,\n    train_data: Union[str, pd.DataFrame],\n    synth_data: Union[str, pd.DataFrame],\n    text_column: str = \"text\",\n    label_column: str = \"category\",\n    split_ratio: float = 0.2,\n    training_params: list = [0.01, \"cross_entropy\", 5e-5, 8, 8, 4, 0.01],\n    tuning: bool = False,\n    tuning_params: dict = None,\n    model_save_path: str = None,\n    classifier_model_name: str = \"distilbert-base-uncased\",\n    filtered_save_path: str = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Train a small classifier on real labeled data and use it to filter the synthetic dataset by agreement.\n\n    Parameters:\n    - train_data (str or pd.DataFrame): Path or DataFrame of small labeled training set.\n    - synth_data (str or pd.DataFrame): Path or DataFrame of generated synthetic dataset.\n    - text_column (str): Name of the text column.\n    - label_column (str): Name of the label column.\n    - split_ratio (float): Ratio for train/test split.\n    - training_params (list): Training hyperparameters.\n    - tuning (bool): Whether to perform hyperparameter tuning using Optuna.\n    - tuning_params (dict): Optional tuning grid.\n    - model_save_path (str): Optional path to save the classifier model.\n    - classifier_model_name (str): HF model ID for the classifier.\n    - filtered_save_path (str): Optional path to save filtered synthetic dataset.\n\n    Returns:\n    - pd.DataFrame: Filtered synthetic dataset based on classifier agreement.\n    \"\"\"\n    if isinstance(train_data, pd.DataFrame) and train_data.empty:\n        raise ValueError(\"Provided training DataFrame is empty.\")\n    if isinstance(synth_data, pd.DataFrame) and synth_data.empty:\n        raise ValueError(\"Provided synthetic DataFrame is empty.\")\n\n    tokenizer = load_tokenizer(classifier_model_name)\n\n    dataset_dict, label2id = load_and_prepare_dataset(\n        train_data, text_column, label_column, split_ratio\n    )\n\n    tokenized = tokenize_dataset(dataset_dict, tokenizer)\n\n    model, trainer = train_model(\n        tokenized,\n        classifier_model_name,\n        len(label2id),\n        training_params,\n        tuning,\n        tuning_params,\n    )\n\n    trainer.evaluate()\n\n    if model_save_path:\n        save_model_and_tokenizer(model, tokenizer, model_save_path)\n\n    df_filtered = filter_synthesized_data(\n        synth_input=synth_data,\n        model=model,\n        tokenizer=tokenizer,\n        label_column=label_column,\n        save_path=filtered_save_path,\n    )\n\n    return df_filtered\n</code></pre>"},{"location":"api/api_frame_gen/#educhateval.core.FrameworkGenerator.generate_framework","title":"<code>generate_framework(prompt_path=None, prompt_dict_input=None, num_samples=500, json_out=None, csv_out=None, seed=42, temperature=0.85, top_p=0.9)</code>","text":"<p>Generate a synthetic labeled dataset from prompts using a language model.</p> <p>Either <code>prompt_path</code> (path to .py file with <code>prompt_dict</code>) or <code>prompt_dict_input</code> must be provided.</p> <p>Parameters: - prompt_path (str): Path to a Python file containing a prompt dictionary. - prompt_dict_input (dict): Prompt dictionary directly provided. - num_samples (int): Number of samples to generate per category. - json_out (str): Optional path to save JSON output. - csv_out (str): Optional path to save CSV output. - seed (int): Random seed for reproducibility.</p> <p>Returns: - pd.DataFrame: Cleaned, labeled synthetic dataset.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>def generate_framework(\n    self,\n    prompt_path: str = None,\n    prompt_dict_input: dict = None,\n    num_samples: int = 500,\n    json_out: str = None,\n    csv_out: str = None,\n    seed: int = 42,\n    temperature: float = 0.85,\n    top_p: float = 0.90,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Generate a synthetic labeled dataset from prompts using a language model.\n\n    Either `prompt_path` (path to .py file with `prompt_dict`) or `prompt_dict_input` must be provided.\n\n    Parameters:\n    - prompt_path (str): Path to a Python file containing a prompt dictionary.\n    - prompt_dict_input (dict): Prompt dictionary directly provided.\n    - num_samples (int): Number of samples to generate per category.\n    - json_out (str): Optional path to save JSON output.\n    - csv_out (str): Optional path to save CSV output.\n    - seed (int): Random seed for reproducibility.\n\n    Returns:\n    - pd.DataFrame: Cleaned, labeled synthetic dataset.\n    \"\"\"\n    if not prompt_path and not prompt_dict_input:\n        raise ValueError(\n            \"You must provide either a prompt_path or prompt_dict_input.\"\n        )\n\n    set_seed(seed)\n\n    df = synthesize_dataset(\n        prompt_dict=prompt_dict_input,\n        prompt_path=prompt_path,\n        model_name=self.model_name,\n        num_samples=num_samples,\n        api_url=self.api_url,\n        json_out=json_out,\n        csv_out=csv_out,\n        temperature=temperature,\n        top_p=top_p,\n    )\n\n    return df\n</code></pre>"},{"location":"api/api_pred/","title":"Predict Labels","text":"<p>This is a test displaying: </p> <p>A wrapper for training and applying a text classification model.</p> <p>This class streamlines the process of fine-tuning a transformer-based classifier on labeled data and applying the trained model to annotate new, unlabeled datasets. Supports both single and multi-column predictions and includes optional model saving and evaluation output.</p> Required Args <p>model_name (str): Name of the pretrained Hugging Face model to fine-tune (default: \"distilbert-base-uncased\").</p> <p>Methods:</p> Name Description <code>run_pipeline</code> <p>Trains the classifier and returns a DataFrame with predicted labels and confidence scores.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>class PredictLabels:\n    \"\"\"\n    A wrapper for training and applying a text classification model.\n\n    This class streamlines the process of fine-tuning a transformer-based classifier on labeled data\n    and applying the trained model to annotate new, unlabeled datasets. Supports both single and multi-column\n    predictions and includes optional model saving and evaluation output.\n\n    Required Args:\n        model_name (str): Name of the pretrained Hugging Face model to fine-tune (default: \"distilbert-base-uncased\").\n\n    Methods:\n        run_pipeline(...): Trains the classifier and returns a DataFrame with predicted labels and confidence scores.\n    \"\"\"\n\n    def __init__(self, model_name: str = \"distilbert-base-uncased\"):\n        self.model_name = model_name\n        self.tokenizer = load_tokenizer(model_name)\n\n    def run_pipeline(\n        self,\n        train_data: Union[str, pd.DataFrame],\n        new_data: Union[str, pd.DataFrame],\n        # columns in the training data\n        text_column: str = \"text\",\n        label_column: str = \"category\",\n        # columns to classify in the new data\n        columns_to_classify: Optional[Union[str, List[str]]] = None,\n        split_ratio: float = 0.2,\n        training_params: list = [0.01, \"cross_entropy\", 5e-5, 8, 8, 4, 0.01],\n        tuning: bool = False,\n        tuning_params: Optional[dict] = None,\n        model_save_path: Optional[str] = None,\n        prediction_save_path: Optional[str] = None,\n        seed: int = 42,\n    ) -&gt; pd.DataFrame:\n\n        # Validate training data input\n        if not isinstance(train_data, (pd.DataFrame, str)):\n            raise ValueError(\n                \"Please provide data training data. This must be a pandas DataFrame or a path to a CSV file.\"\n            )\n\n        if not isinstance(new_data, (pd.DataFrame, str)):\n            raise ValueError(\n                \"Please provide data to be labeled. This must be a pandas DataFrame or a path to a CSV file.\"\n            )\n\n        # Validate training parameters\n        if not isinstance(training_params, list) or len(training_params) &lt; 7:\n            raise ValueError(\n                \"training_params must be a list of at least 7 hyperparameter values.\"\n            )\n\n        if not isinstance(split_ratio, float) or not (0.0 &lt; split_ratio &lt; 1.0):\n            raise ValueError(\"split_ratio must be a float between 0 and 1.\")\n\n        # Validate column names\n        if not isinstance(text_column, str):\n            raise ValueError(\"text_column must be a string.\")\n        if not isinstance(label_column, str):\n            raise ValueError(\"label_column must be a string.\")\n\n        # Validate columns_to_classify\n        if columns_to_classify is not None:\n            if not isinstance(columns_to_classify, (str, list)):\n                raise ValueError(\n                    \"columns_to_classify must be a string or a list of strings.\"\n                )\n            if isinstance(columns_to_classify, list) and not all(\n                isinstance(col, str) for col in columns_to_classify\n            ):\n                raise ValueError(\"All entries in columns_to_classify must be strings.\")\n\n        set_seed(seed)\n\n        dataset_dict, label2id = load_and_prepare_dataset(\n            train_data, text_column, label_column, split_ratio\n        )\n        tokenized = tokenize_dataset(dataset_dict, self.tokenizer)\n\n        model, trainer = train_model(\n            tokenized,\n            self.model_name,\n            len(label2id),\n            training_params,\n            tuning,\n            tuning_params,\n        )\n\n        if model_save_path:\n            save_model_and_tokenizer(model, self.tokenizer, model_save_path)\n\n        # Default to using the training text_column if no specific columns_to_classify provided\n        if columns_to_classify is None:\n            columns_to_classify = text_column\n\n        df_annotated = predict_annotated_dataset(\n            new_data=new_data,\n            model=model,\n            text_columns=columns_to_classify,\n            tokenizer=self.tokenizer,\n            label2id=label2id,\n            save_path=prediction_save_path,\n        )\n\n        return df_annotated\n</code></pre>"},{"location":"api/api_synth_int/","title":"Synthesis Interaction","text":"<p>This is a test displaying: </p> <p>A modular simulator for generating multi-turn dialogues between a student and tutor agent using large language models.</p> <p>This class wraps backend-specific model interfaces and orchestrates the simulation of goal-driven conversations across various educational modes. It supports customizable sampling behavior and ensures reproducibility via global seeding. Outputs are returned as structured pandas DataFrames.</p> <p>Attributes:</p> Name Type Description <code>backend</code> <code>str</code> <p>Backend to use for inference. Options are \"hf\" (Hugging Face) or \"mlx\" (MLX).</p> <code>model_id</code> <code>str</code> <p>The identifier of the model to use, e.g., \"gpt2\" or an MLX-compatible model.</p> <code>sampling_params</code> <code>Optional[dict]</code> <p>Sampling hyperparameters such as temperature, top_p, or top_k.</p> <p>Methods:</p> Name Description <code>simulate_dialogue</code> <p>Simulates a dialogue and returns it as a pandas DataFrame.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>class DialogueSimulator:\n    \"\"\"\n    A modular simulator for generating multi-turn dialogues between a student and tutor agent using large language models.\n\n    This class wraps backend-specific model interfaces and orchestrates the simulation of goal-driven conversations across various educational modes.\n    It supports customizable sampling behavior and ensures reproducibility via global seeding. Outputs are returned as structured pandas DataFrames.\n\n    Attributes:\n        backend (str): Backend to use for inference. Options are \"hf\" (Hugging Face) or \"mlx\" (MLX).\n        model_id (str): The identifier of the model to use, e.g., \"gpt2\" or an MLX-compatible model.\n        sampling_params (Optional[dict]): Sampling hyperparameters such as temperature, top_p, or top_k.\n\n    Methods:\n        simulate_dialogue(...): Simulates a dialogue and returns it as a pandas DataFrame.\n    \"\"\"\n\n    def __init__(\n        self,\n        backend: str = \"mlx\",\n        model_id: str = \"mlx-community/Qwen2.5-7B-Instruct-1M-4bit\",\n        sampling_params: Optional[dict] = None,\n    ):\n        if backend == \"hf\":\n            self.model = ChatHF(\n                model_id=model_id,\n                sampling_params=sampling_params\n                or {\"temperature\": 0.9, \"top_p\": 0.9, \"top_k\": 50},\n            )\n        elif backend == \"mlx\":\n            self.model = ChatMLX(\n                model_id=model_id,\n                sampling_params=sampling_params\n                or {\"temp\": 0.9, \"top_p\": 0.9, \"top_k\": 40},\n            )\n        else:\n            raise ValueError(\"Unsupported backend\")\n\n        self.model.load()\n\n    def simulate_dialogue(\n        self,\n        mode: str = \"general_task_solving\",\n        turns: int = 5,\n        seed_message_input: str = \"Hi, I'm a student seeking assistance with my studies.\",\n        log_dir: Optional[Path] = None,\n        save_csv_path: Optional[Path] = None,\n        seed: int = 42,\n        custom_prompt_file: Optional[Path] = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Simulates a multi-turn dialogue using either built-in or custom prompts.\n\n        Args:\n            mode: Mode key to select prompt pair (student/tutor).\n            turns: Number of back-and-forth turns to simulate.\n            seed_message_input: First message from the student.\n            log_dir: Directory to save raw log (optional).\n            save_csv_path: Path to save structured DataFrame (optional).\n            seed: Random seed for reproducibility.\n            custom_prompt_file: Optional path to custom YAML defining prompt modes.\n\n        Returns:\n            pd.DataFrame: Structured DataFrame of the conversation.\n        \"\"\"\n        set_seed(seed)\n\n        # system_prompts = load_prompts_and_seed(mode)\n\n        df = simulate_conversation(\n            model=self.model,\n            turns=turns,\n            seed_message_input=seed_message_input,\n            log_dir=log_dir,\n            save_csv_path=save_csv_path,\n            custom_prompt_file=custom_prompt_file,\n            mode=mode,\n        )\n\n        print(\n            f\"\\n Full dialogue stored in DataFrame: use the returned object or view as `df`\"\n        )\n        return df\n</code></pre>"},{"location":"api/api_synth_int/#educhateval.core.DialogueSimulator.simulate_dialogue","title":"<code>simulate_dialogue(mode='general_task_solving', turns=5, seed_message_input=\"Hi, I'm a student seeking assistance with my studies.\", log_dir=None, save_csv_path=None, seed=42, custom_prompt_file=None)</code>","text":"<p>Simulates a multi-turn dialogue using either built-in or custom prompts.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>Mode key to select prompt pair (student/tutor).</p> <code>'general_task_solving'</code> <code>turns</code> <code>int</code> <p>Number of back-and-forth turns to simulate.</p> <code>5</code> <code>seed_message_input</code> <code>str</code> <p>First message from the student.</p> <code>\"Hi, I'm a student seeking assistance with my studies.\"</code> <code>log_dir</code> <code>Optional[Path]</code> <p>Directory to save raw log (optional).</p> <code>None</code> <code>save_csv_path</code> <code>Optional[Path]</code> <p>Path to save structured DataFrame (optional).</p> <code>None</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>42</code> <code>custom_prompt_file</code> <code>Optional[Path]</code> <p>Optional path to custom YAML defining prompt modes.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Structured DataFrame of the conversation.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>def simulate_dialogue(\n    self,\n    mode: str = \"general_task_solving\",\n    turns: int = 5,\n    seed_message_input: str = \"Hi, I'm a student seeking assistance with my studies.\",\n    log_dir: Optional[Path] = None,\n    save_csv_path: Optional[Path] = None,\n    seed: int = 42,\n    custom_prompt_file: Optional[Path] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Simulates a multi-turn dialogue using either built-in or custom prompts.\n\n    Args:\n        mode: Mode key to select prompt pair (student/tutor).\n        turns: Number of back-and-forth turns to simulate.\n        seed_message_input: First message from the student.\n        log_dir: Directory to save raw log (optional).\n        save_csv_path: Path to save structured DataFrame (optional).\n        seed: Random seed for reproducibility.\n        custom_prompt_file: Optional path to custom YAML defining prompt modes.\n\n    Returns:\n        pd.DataFrame: Structured DataFrame of the conversation.\n    \"\"\"\n    set_seed(seed)\n\n    # system_prompts = load_prompts_and_seed(mode)\n\n    df = simulate_conversation(\n        model=self.model,\n        turns=turns,\n        seed_message_input=seed_message_input,\n        log_dir=log_dir,\n        save_csv_path=save_csv_path,\n        custom_prompt_file=custom_prompt_file,\n        mode=mode,\n    )\n\n    print(\n        f\"\\n Full dialogue stored in DataFrame: use the returned object or view as `df`\"\n    )\n    return df\n</code></pre>"},{"location":"api/api_viz/","title":"Visualizations","text":"<p>This is a test displaying: </p> <p>Visualization class for analyzing predicted dialogue labels. Wraps existing plotting and summary functions from display_result.py.</p>"},{"location":"api/api_viz/#educhateval.core.Visualizer--parameters","title":"Parameters","text":"<p>df : pd.DataFrame     The annotated dataframe containing predicted label columns. student_col : str, optional     Name of the column containing student message predictions. tutor_col : str, optional     Name of the column containing tutor message predictions.</p> <p>Other keyword arguments (**kwargs) are passed through to the internal plotting functions.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>class Visualizer:\n    \"\"\"\n    Visualization class for analyzing predicted dialogue labels.\n    Wraps existing plotting and summary functions from display_result.py.\n\n    Parameters\n    ----------\n    df : pd.DataFrame\n        The annotated dataframe containing predicted label columns.\n    student_col : str, optional\n        Name of the column containing student message predictions.\n    tutor_col : str, optional\n        Name of the column containing tutor message predictions.\n\n    Other keyword arguments (**kwargs) are passed through to the internal plotting functions.\n    \"\"\"\n\n    def plot_turn_trends(self, df, student_col=None, tutor_col=None, **kwargs):\n        \"\"\"Wrapper for turn-based category line plot.\"\"\"\n        return plot_predicted_categories(\n            df, student_col=student_col, tutor_col=tutor_col, **kwargs\n        )\n\n    def plot_category_bars(self, df, student_col=None, tutor_col=None, **kwargs):\n        \"\"\"Wrapper for grouped barplot of predicted categories.\"\"\"\n        return plot_category_bars(\n            df, student_col=student_col, tutor_col=tutor_col, **kwargs\n        )\n\n    def create_summary_table(self, df, student_col=None, tutor_col=None):\n        \"\"\"Wrapper for generating prediction summary table.\"\"\"\n        return create_prediction_summary_table(\n            df, student_col=student_col, tutor_col=tutor_col\n        )\n\n    def plot_history_interaction(\n        self, df, student_col=None, tutor_col=None, focus_agent=\"student\", **kwargs\n    ):\n        \"\"\"Wrapper for barplot showing category transitions from previous turn.\"\"\"\n        return plot_previous_turn_distribution(\n            df,\n            student_col=student_col,\n            tutor_col=tutor_col,\n            focus_agent=focus_agent,\n            **kwargs,\n        )\n</code></pre>"},{"location":"api/api_viz/#educhateval.core.Visualizer.create_summary_table","title":"<code>create_summary_table(df, student_col=None, tutor_col=None)</code>","text":"<p>Wrapper for generating prediction summary table.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>def create_summary_table(self, df, student_col=None, tutor_col=None):\n    \"\"\"Wrapper for generating prediction summary table.\"\"\"\n    return create_prediction_summary_table(\n        df, student_col=student_col, tutor_col=tutor_col\n    )\n</code></pre>"},{"location":"api/api_viz/#educhateval.core.Visualizer.plot_category_bars","title":"<code>plot_category_bars(df, student_col=None, tutor_col=None, **kwargs)</code>","text":"<p>Wrapper for grouped barplot of predicted categories.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>def plot_category_bars(self, df, student_col=None, tutor_col=None, **kwargs):\n    \"\"\"Wrapper for grouped barplot of predicted categories.\"\"\"\n    return plot_category_bars(\n        df, student_col=student_col, tutor_col=tutor_col, **kwargs\n    )\n</code></pre>"},{"location":"api/api_viz/#educhateval.core.Visualizer.plot_history_interaction","title":"<code>plot_history_interaction(df, student_col=None, tutor_col=None, focus_agent='student', **kwargs)</code>","text":"<p>Wrapper for barplot showing category transitions from previous turn.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>def plot_history_interaction(\n    self, df, student_col=None, tutor_col=None, focus_agent=\"student\", **kwargs\n):\n    \"\"\"Wrapper for barplot showing category transitions from previous turn.\"\"\"\n    return plot_previous_turn_distribution(\n        df,\n        student_col=student_col,\n        tutor_col=tutor_col,\n        focus_agent=focus_agent,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api/api_viz/#educhateval.core.Visualizer.plot_turn_trends","title":"<code>plot_turn_trends(df, student_col=None, tutor_col=None, **kwargs)</code>","text":"<p>Wrapper for turn-based category line plot.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>def plot_turn_trends(self, df, student_col=None, tutor_col=None, **kwargs):\n    \"\"\"Wrapper for turn-based category line plot.\"\"\"\n    return plot_predicted_categories(\n        df, student_col=student_col, tutor_col=tutor_col, **kwargs\n    )\n</code></pre>"},{"location":"api/api_wrap_int/","title":"Wrap Interaction","text":""},{"location":"api/api_wrap_int/#this-one-you-need-to-do-on-your-own-kind-of-like-the-tutorial","title":"THIS ONE YOU NEED TO DO ON YOUR OWN KIND OF LIKE THE TUTORIAL !!!!!!!!!","text":""}]}