{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>This package provides an evaluation framework for analyzing interactions between students and LLM-based tutors through classification, simulation, and visualization tools.</p> <p>The package is designed to:</p> <ul> <li>Provide a customized framework for classification, evaluation, and fine-tuning</li> <li>Simulate student\u2013tutor interactions using role-based prompts and seed messages when real data is unavailable</li> <li>Initiate an interface with locally hosted, open-source models (e.g., via LM Studio or Hugging Face)</li> <li>Log interactions in structured formats (JSON/CSV) for downstream analysis</li> <li>Train and applu classifiers to predict customized interaction classes and visualize patterns across conversations</li> </ul>"},{"location":"#user-guides-and-api","title":"User Guides and API","text":"<p>To run the full pipeline, the package requires integration with LM Studio (for local model hosting) and the Hugging Face ecosystem. Step-by-step tutorials are provided in the User Guide section, covering setup, configuration, and usage across all modules\u2014from data generation to classification and visualization.</p> <p>Detailed information on the available classes, functions, and configuration options can be found in the API reference.</p> <p>Be aware, that the package can be run on python 3.12 due to the dependency on ... </p>"},{"location":"about/","title":"About","text":""},{"location":"about/#project","title":"Project","text":"<p>This package was developed as part of a master's thesis in Cognitive Science at Aarhus University. The project explores how interactions between students and LLM-based tutors can be systematically analyzed using natural language processing, classification pipelines, and visualization techniques.</p> <p>The core contribution is the enablement of quantitative evaluation of interaction-based learning by transforming student\u2013tutor exchanges into structured, labeled data. Through classifier-based annotation and modular components for synthetic data generation, interaction simulation, and result visualization, the package enables a reproducible and data-driven approach to studying chatbot-assisted education. It is designed for flexibility across educational and experimental contexts, particularly where interaction analysis is needed beyond traditional self-report methods.</p> <p>The full source code for the EduChatEval package is available on GitHub and is licensed under MIT License</p>"},{"location":"about/#contact","title":"Contact","text":"<p>For questions or collaboration inquiries, feel free to reach out to Laura W Paaby.</p>"},{"location":"about/#acknowledgements","title":"Acknowledgements","text":"<p>This project builds on existing tools and ideas from the open-source community. While specific references are provided within the relevant scripts throughout the repository, the key sources of inspiration are also acknowledged here to highlight the contributions that have shaped the development of this package.</p> <ul> <li> <p>Constraint-Based Data Generation \u2013 Outlines Package: Willard, Brandon T. &amp; Louf, R\u00e9mi (2023). Efficient Guided Generation for LLMs. </p> </li> <li> <p>Chat Interface and Wrapper \u2013 Textual: McGugan, W. (2024, Sep). Anatomy of a Textual User Interface.</p> </li> <li> <p>Package Design Inspiration: Thea Rolskov Sloth &amp; Astrid Sletten Rybner </p> </li> <li> <p>Code Debugging and Conceptual Feedback:   Mina Almasi and Ross Deans Kristensen-McLachlan</p> </li> </ul>"},{"location":"installation/","title":"Installation","text":"<p>You can install EduChatEval using via pip from PyPI:</p> <p><code>pip install educhateval</code></p> <p>Or from Github:</p> <p><code>pip install git+https://github.com/laurawpaaby/EduChatEval.git</code></p>"},{"location":"api/api_frame_gen/","title":"Framework Generator","text":"<p>Module for generating synthetic annotated datasets (frameworks) using instruction-tuned models hosted locally and filtering of low-quality examples via classifier agreement.</p> <p>Attributes:</p> Name Type Description <code>model_name</code> <code>str</code> <p>Name of the local model to use for generation (default: \"llama-3.2-3b-instruct\").</p> <code>api_url</code> <code>str</code> <p>URL for the local model API (default: \"http://localhost:1234/v1/completions\").</p> <p>Methods:</p> Name Description <code>generate_framework</code> <p>Simulates a dialogue and returns it as a pandas DataFrame.</p> <code>filter_with_classifier</code> <p>Filters the generated dataset using a small classifier trained on real labeled data.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>class FrameworkGenerator:\n    \"\"\"\n    Module for generating synthetic annotated datasets (frameworks) using instruction-tuned models hosted locally and filtering of low-quality examples via classifier agreement.\n\n    Attributes:\n        model_name (str): Name of the local model to use for generation (default: \"llama-3.2-3b-instruct\").\n        api_url (str): URL for the local model API (default: \"http://localhost:1234/v1/completions\").\n\n    Methods:\n        generate_framework(...): Simulates a dialogue and returns it as a pandas DataFrame.\n        filter_with_classifier(...): Filters the generated dataset using a small classifier trained on real labeled data.\n    \"\"\"\n\n    def __init__(\n        self,\n        model_name: str = \"llama-3.2-3b-instruct\",\n        api_url: str = \"http://localhost:1234/v1/completions\",\n    ):\n        self.model_name = model_name\n        self.api_url = api_url\n\n    def generate_framework(\n        self,\n        prompt_path: str = None,\n        prompt_dict_input: dict = None,\n        num_samples: int = 500,\n        json_out: str = None,\n        csv_out: str = None,\n        seed: int = 42,\n        temperature: float = 0.85,\n        top_p: float = 0.90,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Generate a synthetic labeled dataset from prompts using a language model.\n        Either `prompt_path` (path to .py file with `prompt_dict`) or `prompt_dict_input` must be provided.\n\n        Parameters:\n            prompt_path (str): Path to a Python file containing a prompt dictionary.\n            prompt_dict_input (dict): Prompt dictionary directly provided.\n            num_samples (int): Number of samples to generate per category.\n            json_out (str): Optional path to save JSON output.\n            csv_out (str): Optional path to save CSV output.\n            seed (int): Random seed for reproducibility.\n\n        Returns:\n            pd.DataFrame: Cleaned, labeled synthetic dataset.\n        \"\"\"\n        if not prompt_path and not prompt_dict_input:\n            raise ValueError(\n                \"You must provide either a prompt_path or prompt_dict_input.\"\n            )\n\n        set_seed(seed)\n\n        df = synthesize_dataset(\n            prompt_dict=prompt_dict_input,\n            prompt_path=prompt_path,\n            model_name=self.model_name,\n            num_samples=num_samples,\n            api_url=self.api_url,\n            json_out=json_out,\n            csv_out=csv_out,\n            temperature=temperature,\n            top_p=top_p,\n        )\n\n        return df\n\n    #### 2. function to quality check the dataset\n    def filter_with_classifier(\n        self,\n        train_data: Union[str, pd.DataFrame],\n        synth_data: Union[str, pd.DataFrame],\n        text_column: str = \"text\",\n        label_column: str = \"category\",\n        split_ratio: float = 0.2,\n        training_params: list = [0.01, \"cross_entropy\", 5e-5, 8, 8, 4, 0.01],\n        tuning: bool = False,\n        tuning_params: dict = None,\n        model_save_path: str = None,\n        classifier_model_name: str = \"distilbert-base-uncased\",\n        filtered_save_path: str = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Train a small classifier on real labeled data and use it to filter the synthetic dataset by agreement.\n\n        Parameters:\n            train_data (str or pd.DataFrame): Path or DataFrame of small labeled training set.\n            synth_data (str or pd.DataFrame): Path or DataFrame of generated synthetic dataset.\n            text_column (str): Name of the text column.\n            label_column (str): Name of the label column.\n            split_ratio (float): Ratio for train/test split.\n            training_params (list): Training hyperparameters.\n            tuning (bool): Whether to perform hyperparameter tuning using Optuna.\n            tuning_params (dict): Optional tuning grid.\n            model_save_path (str): Optional path to save the classifier model.\n            classifier_model_name (str): HF model ID for the classifier.\n            filtered_save_path (str): Optional path to save filtered synthetic dataset.\n\n        Returns:\n            pd.DataFrame: Filtered synthetic dataset based on classifier agreement.\n        \"\"\"\n        if isinstance(train_data, pd.DataFrame) and train_data.empty:\n            raise ValueError(\"Provided training DataFrame is empty.\")\n        if isinstance(synth_data, pd.DataFrame) and synth_data.empty:\n            raise ValueError(\"Provided synthetic DataFrame is empty.\")\n\n        tokenizer = load_tokenizer(classifier_model_name)\n\n        dataset_dict, label2id = load_and_prepare_dataset(\n            train_data, text_column, label_column, split_ratio\n        )\n\n        tokenized = tokenize_dataset(dataset_dict, tokenizer)\n\n        model, trainer = train_model(\n            tokenized,\n            classifier_model_name,\n            len(label2id),\n            training_params,\n            tuning,\n            tuning_params,\n        )\n\n        trainer.evaluate()\n\n        if model_save_path:\n            save_model_and_tokenizer(model, tokenizer, model_save_path)\n\n        df_filtered = filter_synthesized_data(\n            synth_input=synth_data,\n            model=model,\n            tokenizer=tokenizer,\n            label_column=label_column,\n            save_path=filtered_save_path,\n        )\n\n        return df_filtered\n</code></pre>"},{"location":"api/api_frame_gen/#educhateval.core.FrameworkGenerator.generate_framework","title":"<code>generate_framework(prompt_path=None, prompt_dict_input=None, num_samples=500, json_out=None, csv_out=None, seed=42, temperature=0.85, top_p=0.9)</code>","text":"<p>Generate a synthetic labeled dataset from prompts using a language model. Either <code>prompt_path</code> (path to .py file with <code>prompt_dict</code>) or <code>prompt_dict_input</code> must be provided.</p> <p>Parameters:</p> Name Type Description Default <code>prompt_path</code> <code>str</code> <p>Path to a Python file containing a prompt dictionary.</p> <code>None</code> <code>prompt_dict_input</code> <code>dict</code> <p>Prompt dictionary directly provided.</p> <code>None</code> <code>num_samples</code> <code>int</code> <p>Number of samples to generate per category.</p> <code>500</code> <code>json_out</code> <code>str</code> <p>Optional path to save JSON output.</p> <code>None</code> <code>csv_out</code> <code>str</code> <p>Optional path to save CSV output.</p> <code>None</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>42</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Cleaned, labeled synthetic dataset.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>def generate_framework(\n    self,\n    prompt_path: str = None,\n    prompt_dict_input: dict = None,\n    num_samples: int = 500,\n    json_out: str = None,\n    csv_out: str = None,\n    seed: int = 42,\n    temperature: float = 0.85,\n    top_p: float = 0.90,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Generate a synthetic labeled dataset from prompts using a language model.\n    Either `prompt_path` (path to .py file with `prompt_dict`) or `prompt_dict_input` must be provided.\n\n    Parameters:\n        prompt_path (str): Path to a Python file containing a prompt dictionary.\n        prompt_dict_input (dict): Prompt dictionary directly provided.\n        num_samples (int): Number of samples to generate per category.\n        json_out (str): Optional path to save JSON output.\n        csv_out (str): Optional path to save CSV output.\n        seed (int): Random seed for reproducibility.\n\n    Returns:\n        pd.DataFrame: Cleaned, labeled synthetic dataset.\n    \"\"\"\n    if not prompt_path and not prompt_dict_input:\n        raise ValueError(\n            \"You must provide either a prompt_path or prompt_dict_input.\"\n        )\n\n    set_seed(seed)\n\n    df = synthesize_dataset(\n        prompt_dict=prompt_dict_input,\n        prompt_path=prompt_path,\n        model_name=self.model_name,\n        num_samples=num_samples,\n        api_url=self.api_url,\n        json_out=json_out,\n        csv_out=csv_out,\n        temperature=temperature,\n        top_p=top_p,\n    )\n\n    return df\n</code></pre>"},{"location":"api/api_frame_gen/#educhateval.core.FrameworkGenerator.filter_with_classifier","title":"<code>filter_with_classifier(train_data, synth_data, text_column='text', label_column='category', split_ratio=0.2, training_params=[0.01, 'cross_entropy', 5e-05, 8, 8, 4, 0.01], tuning=False, tuning_params=None, model_save_path=None, classifier_model_name='distilbert-base-uncased', filtered_save_path=None)</code>","text":"<p>Train a small classifier on real labeled data and use it to filter the synthetic dataset by agreement.</p> <p>Parameters:</p> Name Type Description Default <code>train_data</code> <code>str or DataFrame</code> <p>Path or DataFrame of small labeled training set.</p> required <code>synth_data</code> <code>str or DataFrame</code> <p>Path or DataFrame of generated synthetic dataset.</p> required <code>text_column</code> <code>str</code> <p>Name of the text column.</p> <code>'text'</code> <code>label_column</code> <code>str</code> <p>Name of the label column.</p> <code>'category'</code> <code>split_ratio</code> <code>float</code> <p>Ratio for train/test split.</p> <code>0.2</code> <code>training_params</code> <code>list</code> <p>Training hyperparameters.</p> <code>[0.01, 'cross_entropy', 5e-05, 8, 8, 4, 0.01]</code> <code>tuning</code> <code>bool</code> <p>Whether to perform hyperparameter tuning using Optuna.</p> <code>False</code> <code>tuning_params</code> <code>dict</code> <p>Optional tuning grid.</p> <code>None</code> <code>model_save_path</code> <code>str</code> <p>Optional path to save the classifier model.</p> <code>None</code> <code>classifier_model_name</code> <code>str</code> <p>HF model ID for the classifier.</p> <code>'distilbert-base-uncased'</code> <code>filtered_save_path</code> <code>str</code> <p>Optional path to save filtered synthetic dataset.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Filtered synthetic dataset based on classifier agreement.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>def filter_with_classifier(\n    self,\n    train_data: Union[str, pd.DataFrame],\n    synth_data: Union[str, pd.DataFrame],\n    text_column: str = \"text\",\n    label_column: str = \"category\",\n    split_ratio: float = 0.2,\n    training_params: list = [0.01, \"cross_entropy\", 5e-5, 8, 8, 4, 0.01],\n    tuning: bool = False,\n    tuning_params: dict = None,\n    model_save_path: str = None,\n    classifier_model_name: str = \"distilbert-base-uncased\",\n    filtered_save_path: str = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Train a small classifier on real labeled data and use it to filter the synthetic dataset by agreement.\n\n    Parameters:\n        train_data (str or pd.DataFrame): Path or DataFrame of small labeled training set.\n        synth_data (str or pd.DataFrame): Path or DataFrame of generated synthetic dataset.\n        text_column (str): Name of the text column.\n        label_column (str): Name of the label column.\n        split_ratio (float): Ratio for train/test split.\n        training_params (list): Training hyperparameters.\n        tuning (bool): Whether to perform hyperparameter tuning using Optuna.\n        tuning_params (dict): Optional tuning grid.\n        model_save_path (str): Optional path to save the classifier model.\n        classifier_model_name (str): HF model ID for the classifier.\n        filtered_save_path (str): Optional path to save filtered synthetic dataset.\n\n    Returns:\n        pd.DataFrame: Filtered synthetic dataset based on classifier agreement.\n    \"\"\"\n    if isinstance(train_data, pd.DataFrame) and train_data.empty:\n        raise ValueError(\"Provided training DataFrame is empty.\")\n    if isinstance(synth_data, pd.DataFrame) and synth_data.empty:\n        raise ValueError(\"Provided synthetic DataFrame is empty.\")\n\n    tokenizer = load_tokenizer(classifier_model_name)\n\n    dataset_dict, label2id = load_and_prepare_dataset(\n        train_data, text_column, label_column, split_ratio\n    )\n\n    tokenized = tokenize_dataset(dataset_dict, tokenizer)\n\n    model, trainer = train_model(\n        tokenized,\n        classifier_model_name,\n        len(label2id),\n        training_params,\n        tuning,\n        tuning_params,\n    )\n\n    trainer.evaluate()\n\n    if model_save_path:\n        save_model_and_tokenizer(model, tokenizer, model_save_path)\n\n    df_filtered = filter_synthesized_data(\n        synth_input=synth_data,\n        model=model,\n        tokenizer=tokenizer,\n        label_column=label_column,\n        save_path=filtered_save_path,\n    )\n\n    return df_filtered\n</code></pre>"},{"location":"api/api_pred/","title":"Predicting Labels","text":"<p>Module for training and applying a text classification model.</p> <p>This class streamlines the process of fine-tuning a transformer-based classifier on labeled data and applying the trained model to annotate new, unlabeled datasets. Supports both single and multi-column predictions and includes optional model saving and evaluation output.</p> <p>Attributes:</p> Name Type Description <code>model_name</code> <code>str</code> <p>Name of the pretrained Hugging Face model to fine-tune (default: \"distilbert-base-uncased\").</p> <p>Methods:</p> Name Description <code>run_pipeline</code> <p>Trains the classifier and returns a DataFrame with predicted labels and confidence scores.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>class PredictLabels:\n    \"\"\"\n    Module for training and applying a text classification model.\n\n    This class streamlines the process of fine-tuning a transformer-based classifier on labeled data\n    and applying the trained model to annotate new, unlabeled datasets. Supports both single and multi-column\n    predictions and includes optional model saving and evaluation output.\n\n    Attributes:\n        model_name (str): Name of the pretrained Hugging Face model to fine-tune (default: \"distilbert-base-uncased\").\n\n    Methods:\n        run_pipeline(...): Trains the classifier and returns a DataFrame with predicted labels and confidence scores.\n    \"\"\"\n\n    def __init__(self, model_name: str = \"distilbert-base-uncased\"):\n        self.model_name = model_name\n        self.tokenizer = load_tokenizer(model_name)\n\n    def run_pipeline(\n        self,\n        train_data: Union[str, pd.DataFrame],\n        new_data: Union[str, pd.DataFrame],\n        # columns in the training data\n        text_column: str = \"text\",\n        label_column: str = \"category\",\n        # columns to classify in the new data\n        columns_to_classify: Optional[Union[str, List[str]]] = None,\n        split_ratio: float = 0.2,\n        training_params: list = [0.01, \"cross_entropy\", 5e-5, 8, 8, 4, 0.01],\n        tuning: bool = False,\n        tuning_params: Optional[dict] = None,\n        model_save_path: Optional[str] = None,\n        prediction_save_path: Optional[str] = None,\n        seed: int = 42,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        This function handles the full pipeline of loading data, preparing datasets, tokenizing inputs, training a transformer-based\n        classifier, and applying it to specified text columns in new data. It supports custom hyperparameters, optional hyperparameter\n        tuning, and saving of both the trained model and prediction outputs.\n\n        Parameters:\n            train_data (Union[str, pd.DataFrame]): Labeled dataset for training. Can be a DataFrame or a CSV file path.\n            new_data (Union[str, pd.DataFrame]): Dataset to annotate with predicted labels. Can be a DataFrame or a CSV file path.\n            text_column (str): Column in the training data containing the input text. Defaults to \"text\".\n            label_column (str): Column in the training data containing the target labels. Defaults to \"category\".\n            columns_to_classify (Optional[Union[str, List[str]]]): Column(s) in `new_data` to predict labels for. Defaults to `text_column`.\n            split_ratio (float): Ratio of data to use for validation. Must be between 0 and 1. Defaults to 0.2.\n            training_params (list): List of 7 training hyperparameters: [weight_decay, loss_fn, learning_rate, batch_size,\n                                num_epochs, warmup_steps, gradient_accumulation]. Defaults to [0.01, \"cross_entropy\", 5e-5, 8, 8, 4, 0.01].\n            tuning (bool): Whether to perform hyperparameter tuning. Defaults to False.\n            tuning_params (Optional[dict]): Dictionary of tuning settings if `tuning` is True. Defaults to None.\n            model_save_path (Optional[str]): Optional path to save the trained model and tokenizer. Defaults to None.\n            prediction_save_path (Optional[str]): Optional path to save annotated predictions as a CSV. Defaults to None.\n            seed (int): Random seed for reproducibility. Defaults to 42.\n\n        Returns:\n            pd.DataFrame: A DataFrame containing the original `new_data` with added columns for predicted labels and confidence scores.\n        \"\"\"\n\n\n        # Validate training data input\n        if not isinstance(train_data, (pd.DataFrame, str)):\n            raise ValueError(\n                \"Please provide data training data. This must be a pandas DataFrame or a path to a CSV file.\"\n            )\n\n        if not isinstance(new_data, (pd.DataFrame, str)):\n            raise ValueError(\n                \"Please provide data to be labeled. This must be a pandas DataFrame or a path to a CSV file.\"\n            )\n\n        # Validate training parameters\n        if not isinstance(training_params, list) or len(training_params) &lt; 7:\n            raise ValueError(\n                \"training_params must be a list of at least 7 hyperparameter values.\"\n            )\n\n        if not isinstance(split_ratio, float) or not (0.0 &lt; split_ratio &lt; 1.0):\n            raise ValueError(\"split_ratio must be a float between 0 and 1.\")\n\n        # Validate column names\n        if not isinstance(text_column, str):\n            raise ValueError(\"text_column must be a string.\")\n        if not isinstance(label_column, str):\n            raise ValueError(\"label_column must be a string.\")\n\n        # Validate columns_to_classify\n        if columns_to_classify is not None:\n            if not isinstance(columns_to_classify, (str, list)):\n                raise ValueError(\n                    \"columns_to_classify must be a string or a list of strings.\"\n                )\n            if isinstance(columns_to_classify, list) and not all(\n                isinstance(col, str) for col in columns_to_classify\n            ):\n                raise ValueError(\"All entries in columns_to_classify must be strings.\")\n\n        set_seed(seed)\n\n        dataset_dict, label2id = load_and_prepare_dataset(\n            train_data, text_column, label_column, split_ratio\n        )\n        tokenized = tokenize_dataset(dataset_dict, self.tokenizer)\n\n        model, trainer = train_model(\n            tokenized,\n            self.model_name,\n            len(label2id),\n            training_params,\n            tuning,\n            tuning_params,\n        )\n\n        if model_save_path:\n            save_model_and_tokenizer(model, self.tokenizer, model_save_path)\n\n        # Default to using the training text_column if no specific columns_to_classify provided\n        if columns_to_classify is None:\n            columns_to_classify = text_column\n\n        df_annotated = predict_annotated_dataset(\n            new_data=new_data,\n            model=model,\n            text_columns=columns_to_classify,\n            tokenizer=self.tokenizer,\n            label2id=label2id,\n            save_path=prediction_save_path,\n        )\n\n        return df_annotated\n</code></pre>"},{"location":"api/api_pred/#educhateval.core.PredictLabels.run_pipeline","title":"<code>run_pipeline(train_data, new_data, text_column='text', label_column='category', columns_to_classify=None, split_ratio=0.2, training_params=[0.01, 'cross_entropy', 5e-05, 8, 8, 4, 0.01], tuning=False, tuning_params=None, model_save_path=None, prediction_save_path=None, seed=42)</code>","text":"<p>This function handles the full pipeline of loading data, preparing datasets, tokenizing inputs, training a transformer-based classifier, and applying it to specified text columns in new data. It supports custom hyperparameters, optional hyperparameter tuning, and saving of both the trained model and prediction outputs.</p> <p>Parameters:</p> Name Type Description Default <code>train_data</code> <code>Union[str, DataFrame]</code> <p>Labeled dataset for training. Can be a DataFrame or a CSV file path.</p> required <code>new_data</code> <code>Union[str, DataFrame]</code> <p>Dataset to annotate with predicted labels. Can be a DataFrame or a CSV file path.</p> required <code>text_column</code> <code>str</code> <p>Column in the training data containing the input text. Defaults to \"text\".</p> <code>'text'</code> <code>label_column</code> <code>str</code> <p>Column in the training data containing the target labels. Defaults to \"category\".</p> <code>'category'</code> <code>columns_to_classify</code> <code>Optional[Union[str, List[str]]]</code> <p>Column(s) in <code>new_data</code> to predict labels for. Defaults to <code>text_column</code>.</p> <code>None</code> <code>split_ratio</code> <code>float</code> <p>Ratio of data to use for validation. Must be between 0 and 1. Defaults to 0.2.</p> <code>0.2</code> <code>training_params</code> <code>list</code> <p>List of 7 training hyperparameters: [weight_decay, loss_fn, learning_rate, batch_size,                 num_epochs, warmup_steps, gradient_accumulation]. Defaults to [0.01, \"cross_entropy\", 5e-5, 8, 8, 4, 0.01].</p> <code>[0.01, 'cross_entropy', 5e-05, 8, 8, 4, 0.01]</code> <code>tuning</code> <code>bool</code> <p>Whether to perform hyperparameter tuning. Defaults to False.</p> <code>False</code> <code>tuning_params</code> <code>Optional[dict]</code> <p>Dictionary of tuning settings if <code>tuning</code> is True. Defaults to None.</p> <code>None</code> <code>model_save_path</code> <code>Optional[str]</code> <p>Optional path to save the trained model and tokenizer. Defaults to None.</p> <code>None</code> <code>prediction_save_path</code> <code>Optional[str]</code> <p>Optional path to save annotated predictions as a CSV. Defaults to None.</p> <code>None</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility. Defaults to 42.</p> <code>42</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A DataFrame containing the original <code>new_data</code> with added columns for predicted labels and confidence scores.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>def run_pipeline(\n    self,\n    train_data: Union[str, pd.DataFrame],\n    new_data: Union[str, pd.DataFrame],\n    # columns in the training data\n    text_column: str = \"text\",\n    label_column: str = \"category\",\n    # columns to classify in the new data\n    columns_to_classify: Optional[Union[str, List[str]]] = None,\n    split_ratio: float = 0.2,\n    training_params: list = [0.01, \"cross_entropy\", 5e-5, 8, 8, 4, 0.01],\n    tuning: bool = False,\n    tuning_params: Optional[dict] = None,\n    model_save_path: Optional[str] = None,\n    prediction_save_path: Optional[str] = None,\n    seed: int = 42,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    This function handles the full pipeline of loading data, preparing datasets, tokenizing inputs, training a transformer-based\n    classifier, and applying it to specified text columns in new data. It supports custom hyperparameters, optional hyperparameter\n    tuning, and saving of both the trained model and prediction outputs.\n\n    Parameters:\n        train_data (Union[str, pd.DataFrame]): Labeled dataset for training. Can be a DataFrame or a CSV file path.\n        new_data (Union[str, pd.DataFrame]): Dataset to annotate with predicted labels. Can be a DataFrame or a CSV file path.\n        text_column (str): Column in the training data containing the input text. Defaults to \"text\".\n        label_column (str): Column in the training data containing the target labels. Defaults to \"category\".\n        columns_to_classify (Optional[Union[str, List[str]]]): Column(s) in `new_data` to predict labels for. Defaults to `text_column`.\n        split_ratio (float): Ratio of data to use for validation. Must be between 0 and 1. Defaults to 0.2.\n        training_params (list): List of 7 training hyperparameters: [weight_decay, loss_fn, learning_rate, batch_size,\n                            num_epochs, warmup_steps, gradient_accumulation]. Defaults to [0.01, \"cross_entropy\", 5e-5, 8, 8, 4, 0.01].\n        tuning (bool): Whether to perform hyperparameter tuning. Defaults to False.\n        tuning_params (Optional[dict]): Dictionary of tuning settings if `tuning` is True. Defaults to None.\n        model_save_path (Optional[str]): Optional path to save the trained model and tokenizer. Defaults to None.\n        prediction_save_path (Optional[str]): Optional path to save annotated predictions as a CSV. Defaults to None.\n        seed (int): Random seed for reproducibility. Defaults to 42.\n\n    Returns:\n        pd.DataFrame: A DataFrame containing the original `new_data` with added columns for predicted labels and confidence scores.\n    \"\"\"\n\n\n    # Validate training data input\n    if not isinstance(train_data, (pd.DataFrame, str)):\n        raise ValueError(\n            \"Please provide data training data. This must be a pandas DataFrame or a path to a CSV file.\"\n        )\n\n    if not isinstance(new_data, (pd.DataFrame, str)):\n        raise ValueError(\n            \"Please provide data to be labeled. This must be a pandas DataFrame or a path to a CSV file.\"\n        )\n\n    # Validate training parameters\n    if not isinstance(training_params, list) or len(training_params) &lt; 7:\n        raise ValueError(\n            \"training_params must be a list of at least 7 hyperparameter values.\"\n        )\n\n    if not isinstance(split_ratio, float) or not (0.0 &lt; split_ratio &lt; 1.0):\n        raise ValueError(\"split_ratio must be a float between 0 and 1.\")\n\n    # Validate column names\n    if not isinstance(text_column, str):\n        raise ValueError(\"text_column must be a string.\")\n    if not isinstance(label_column, str):\n        raise ValueError(\"label_column must be a string.\")\n\n    # Validate columns_to_classify\n    if columns_to_classify is not None:\n        if not isinstance(columns_to_classify, (str, list)):\n            raise ValueError(\n                \"columns_to_classify must be a string or a list of strings.\"\n            )\n        if isinstance(columns_to_classify, list) and not all(\n            isinstance(col, str) for col in columns_to_classify\n        ):\n            raise ValueError(\"All entries in columns_to_classify must be strings.\")\n\n    set_seed(seed)\n\n    dataset_dict, label2id = load_and_prepare_dataset(\n        train_data, text_column, label_column, split_ratio\n    )\n    tokenized = tokenize_dataset(dataset_dict, self.tokenizer)\n\n    model, trainer = train_model(\n        tokenized,\n        self.model_name,\n        len(label2id),\n        training_params,\n        tuning,\n        tuning_params,\n    )\n\n    if model_save_path:\n        save_model_and_tokenizer(model, self.tokenizer, model_save_path)\n\n    # Default to using the training text_column if no specific columns_to_classify provided\n    if columns_to_classify is None:\n        columns_to_classify = text_column\n\n    df_annotated = predict_annotated_dataset(\n        new_data=new_data,\n        model=model,\n        text_columns=columns_to_classify,\n        tokenizer=self.tokenizer,\n        label2id=label2id,\n        save_path=prediction_save_path,\n    )\n\n    return df_annotated\n</code></pre>"},{"location":"api/api_synth_int/","title":"Synthesizing Interactions","text":"<p>Module for generating multi-turn dialogues between a student and tutor agent using large language models.</p> <p>This class wraps backend-specific model interfaces and orchestrates the simulation of conversations between two agents. It supports customizable educational modes and sampling behavior and ensures reproducibility via global seeding. Outputs are returned as structured pandas DataFrames.</p> <p>Attributes:</p> Name Type Description <code>backend</code> <code>str</code> <p>Backend to use for inference. Options are \"hf\" (Hugging Face) or \"mlx\" (MLX).</p> <code>model_id</code> <code>str</code> <p>The identifier of the model to use, e.g., \"gpt2\" (Hugging Face) or \"Qwen2.5-7B-Instruct-1M-4bit\" (MLX).</p> <code>sampling_params</code> <code>Optional[dict]</code> <p>Sampling hyperparameters such as temperature, top_p, or top_k.</p> <p>Methods:</p> Name Description <code>simulate_dialogue</code> <p>Simulates a dialogue and returns it as a pandas DataFrame.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>class DialogueSimulator:\n    \"\"\"\n    Module for generating multi-turn dialogues between a student and tutor agent using large language models.\n\n    This class wraps backend-specific model interfaces and orchestrates the simulation of conversations between two agents.\n    It supports customizable educational modes and sampling behavior and ensures reproducibility via global seeding. Outputs are returned as structured pandas DataFrames.\n\n    Attributes:\n        backend (str): Backend to use for inference. Options are \"hf\" (Hugging Face) or \"mlx\" (MLX).\n        model_id (str): The identifier of the model to use, e.g., \"gpt2\" (Hugging Face) or \"Qwen2.5-7B-Instruct-1M-4bit\" (MLX).\n        sampling_params (Optional[dict]): Sampling hyperparameters such as temperature, top_p, or top_k.\n\n    Methods:\n        simulate_dialogue(...): Simulates a dialogue and returns it as a pandas DataFrame.\n    \"\"\"\n\n    def __init__(\n        self,\n        backend: str = \"mlx\",\n        model_id: str = \"mlx-community/Qwen2.5-7B-Instruct-1M-4bit\",\n        sampling_params: Optional[dict] = None,\n    ):\n        if backend == \"hf\":\n            self.model = ChatHF(\n                model_id=model_id,\n                sampling_params=sampling_params\n                or {\"temperature\": 0.9, \"top_p\": 0.9, \"top_k\": 50},\n            )\n        elif backend == \"mlx\":\n            self.model = ChatMLX(\n                model_id=model_id,\n                sampling_params=sampling_params\n                or {\"temp\": 0.9, \"top_p\": 0.9, \"top_k\": 40},\n            )\n        else:\n            raise ValueError(\"Unsupported backend\")\n\n        self.model.load()\n\n    def simulate_dialogue(\n        self,\n        mode: str = \"general_task_solving\",\n        turns: int = 5,\n        seed_message_input: str = \"Hi, I'm a student seeking assistance with my studies.\",\n        log_dir: Optional[Path] = None,\n        save_csv_path: Optional[Path] = None,\n        seed: int = 42,\n        custom_prompt_file: Optional[Path] = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Simulates a multi-turn dialogue using either built-in or custom prompts.\n\n        Args:\n            mode: Mode key to select prompt pair (student/tutor).\n            turns: Number of back-and-forth turns to simulate.\n            seed_message_input: First message from the student.\n            log_dir: Directory to save raw log (optional).\n            save_csv_path: Path to save structured DataFrame (optional).\n            seed: Random seed for reproducibility.\n            custom_prompt_file: Optional path to custom YAML defining prompt modes.\n\n        Returns:\n            pd.DataFrame: Structured DataFrame of the conversation.\n        \"\"\"\n        set_seed(seed)\n\n        # system_prompts = load_prompts_and_seed(mode)\n\n        df = simulate_conversation(\n            model=self.model,\n            turns=turns,\n            seed_message_input=seed_message_input,\n            log_dir=log_dir,\n            save_csv_path=save_csv_path,\n            custom_prompt_file=custom_prompt_file,\n            mode=mode,\n        )\n\n        print(\n            f\"\\n Full dialogue stored in DataFrame: use the returned object or view as `df`\"\n        )\n        return df\n</code></pre>"},{"location":"api/api_synth_int/#educhateval.core.DialogueSimulator.simulate_dialogue","title":"<code>simulate_dialogue(mode='general_task_solving', turns=5, seed_message_input=\"Hi, I'm a student seeking assistance with my studies.\", log_dir=None, save_csv_path=None, seed=42, custom_prompt_file=None)</code>","text":"<p>Simulates a multi-turn dialogue using either built-in or custom prompts.</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>str</code> <p>Mode key to select prompt pair (student/tutor).</p> <code>'general_task_solving'</code> <code>turns</code> <code>int</code> <p>Number of back-and-forth turns to simulate.</p> <code>5</code> <code>seed_message_input</code> <code>str</code> <p>First message from the student.</p> <code>\"Hi, I'm a student seeking assistance with my studies.\"</code> <code>log_dir</code> <code>Optional[Path]</code> <p>Directory to save raw log (optional).</p> <code>None</code> <code>save_csv_path</code> <code>Optional[Path]</code> <p>Path to save structured DataFrame (optional).</p> <code>None</code> <code>seed</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>42</code> <code>custom_prompt_file</code> <code>Optional[Path]</code> <p>Optional path to custom YAML defining prompt modes.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Structured DataFrame of the conversation.</p> Source code in <code>src/educhateval/core.py</code> <pre><code>def simulate_dialogue(\n    self,\n    mode: str = \"general_task_solving\",\n    turns: int = 5,\n    seed_message_input: str = \"Hi, I'm a student seeking assistance with my studies.\",\n    log_dir: Optional[Path] = None,\n    save_csv_path: Optional[Path] = None,\n    seed: int = 42,\n    custom_prompt_file: Optional[Path] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Simulates a multi-turn dialogue using either built-in or custom prompts.\n\n    Args:\n        mode: Mode key to select prompt pair (student/tutor).\n        turns: Number of back-and-forth turns to simulate.\n        seed_message_input: First message from the student.\n        log_dir: Directory to save raw log (optional).\n        save_csv_path: Path to save structured DataFrame (optional).\n        seed: Random seed for reproducibility.\n        custom_prompt_file: Optional path to custom YAML defining prompt modes.\n\n    Returns:\n        pd.DataFrame: Structured DataFrame of the conversation.\n    \"\"\"\n    set_seed(seed)\n\n    # system_prompts = load_prompts_and_seed(mode)\n\n    df = simulate_conversation(\n        model=self.model,\n        turns=turns,\n        seed_message_input=seed_message_input,\n        log_dir=log_dir,\n        save_csv_path=save_csv_path,\n        custom_prompt_file=custom_prompt_file,\n        mode=mode,\n    )\n\n    print(\n        f\"\\n Full dialogue stored in DataFrame: use the returned object or view as `df`\"\n    )\n    return df\n</code></pre>"},{"location":"api/api_viz/","title":"Visualizer","text":"<p>Module for generating four different visualizations to analysis the interactions by.  Every visualization besides the Interaction Distribution plot can be created for either the student, the tutor or both. The Interaction Distribution plot requires both student and tutor data to visualize interactions. </p> <p>1. Barchart of Predicted Classes </p> Source code in <code>src/educhateval/descriptive_results/display_results.py</code> <pre><code>def plot_category_bars(\n    df,\n    student_col=None,\n    tutor_col=None,\n    use_percent=True,\n    palette=\"icefire\",\n    title=\"Predicted Classes\",\n):\n    if not student_col and not tutor_col:\n        raise ValueError(\"You must provide at least one of student_col or tutor_col.\")\n\n    long_dfs = []\n    if student_col:\n        temp = df[[student_col]].copy()\n        temp[\"source\"] = \"Student\"\n        temp.rename(columns={student_col: \"predicted_label\"}, inplace=True)\n        long_dfs.append(temp)\n    if tutor_col:\n        temp = df[[tutor_col]].copy()\n        temp[\"source\"] = \"Tutor\"\n        temp.rename(columns={tutor_col: \"predicted_label\"}, inplace=True)\n        long_dfs.append(temp)\n\n    long_df = pd.concat(long_dfs, ignore_index=True)\n\n    all_labels = sorted(long_df[\"predicted_label\"].dropna().unique())\n    long_df[\"predicted_label\"] = pd.Categorical(\n        long_df[\"predicted_label\"], categories=all_labels, ordered=True\n    )\n\n    count_df = (\n        long_df.groupby([\"source\", \"predicted_label\"], observed=True)\n        .size()\n        .reset_index(name=\"count\")\n    )\n\n    if use_percent:\n        total_per_source = count_df.groupby(\"source\", observed=True)[\"count\"].transform(\n            \"sum\"\n        )\n        count_df[\"value\"] = (count_df[\"count\"] / total_per_source) * 100\n        y_label = \"Occurrences (%)\"\n        fmt = lambda val: f\"{val:.0f}%\"\n    else:\n        count_df[\"value\"] = count_df[\"count\"]\n        y_label = \"Number of Occurrences\"\n        fmt = lambda val: f\"{int(val)}\"\n\n    sns.set_style(\"whitegrid\")\n    plt.figure(figsize=(10, 6))\n\n    ax = sns.barplot(\n        data=count_df,\n        x=\"predicted_label\",\n        y=\"value\",\n        hue=\"source\",\n        palette=palette,\n        order=all_labels,\n    )\n\n    ax.set_xlabel(\"Predicted Category\")\n    ax.set_ylabel(y_label)\n    ax.set_title(title, fontsize=15, fontweight=\"bold\")\n\n    if use_percent:\n        ax.yaxis.set_major_formatter(mtick.FuncFormatter(lambda y, _: f\"{y:.0f}%\"))\n\n    for container in ax.containers:\n        for bar in container:\n            height = bar.get_height()\n            if height &gt; 0:\n                ax.annotate(\n                    fmt(height),\n                    xy=(bar.get_x() + bar.get_width() / 2, height),\n                    xytext=(0, 3),\n                    textcoords=\"offset points\",\n                    ha=\"center\",\n                    va=\"bottom\",\n                    fontsize=9,\n                )\n\n    plt.legend(title=\"Agent\")\n    plt.tight_layout()\n    plt.show()\n</code></pre> <p>Example usage: </p> <pre><code>viz.plot_category_bars(\n    df=annotated_df,\n    student_col=\"predicted_labels_student_msg\",\n    tutor_col=\"predicted_labels_tutor_msg\",\n    use_percent=True,\n    title=\"Distribution of Predicted Classes\"\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> The input DataFrame containing predicted categories for student and/or tutor. required <code>student_col</code> <code>str</code> or <code>None</code> Name of the column with student-predicted labels. Optional. <code>None</code> <code>tutor_col</code> <code>str</code> or <code>None</code> Name of the column with tutor-predicted labels. Optional. <code>None</code> <code>palette</code> <code>str</code> Color palette used for the plot. Optional. <code>\"icefire\"</code> <code>title</code> <code>str</code> Title of the plot. Optional. <code>\"Predicted Classes\"</code> <p>Returns:</p> Name Type Description \u2014 <code>None</code> Displays the plot using <code>matplotlib.pyplot.show()</code>. No object is returned. <p>2. Summary Table </p> Source code in <code>src/educhateval/descriptive_results/display_results.py</code> <pre><code>def create_prediction_summary_table(df, student_col=None, tutor_col=None):\n    if not student_col and not tutor_col:\n        raise ValueError(\"You must provide at least one of student_col or tutor_col.\")\n\n    result_dfs = []\n    all_categories = set()\n\n    if student_col:\n        student_counts = df[student_col].value_counts(dropna=False)\n        total = student_counts.sum()\n        counts = student_counts.rename(\"Student (n)\")\n        percents = ((student_counts / total) * 100).round(1).astype(str) + \"%\"\n        percents.name = \"Student (%)\"\n        merged = pd.concat([counts, percents], axis=1)\n        result_dfs.append(merged)\n        all_categories.update(merged.index)\n\n    if tutor_col:\n        tutor_counts = df[tutor_col].value_counts(dropna=False)\n        total = tutor_counts.sum()\n        counts = tutor_counts.rename(\"Tutor (n)\")\n        percents = ((tutor_counts / total) * 100).round(1).astype(str) + \"%\"\n        percents.name = \"Tutor (%)\"\n        merged = pd.concat([counts, percents], axis=1)\n        result_dfs.append(merged)\n        all_categories.update(merged.index)\n\n    full_index = pd.Index(sorted(all_categories), name=\"Predicted Category\")\n    summary_df = pd.DataFrame(index=full_index)\n\n    for df_part in result_dfs:\n        summary_df = summary_df.join(df_part, how=\"left\")\n\n    for col in summary_df.columns:\n        if \"(n)\" in col:\n            summary_df[col] = summary_df[col].fillna(0).astype(int)\n        elif \"(%)\" in col:\n            summary_df[col] = summary_df[col].fillna(\"0.0%\")\n\n    summary_df = summary_df.reset_index()\n    return summary_df\n</code></pre> <p>Example usage: </p> <pre><code>summary = viz.create_summary_table(\n    df=annotated_df,\n    student_col=\"predicted_labels_student_msg\",\n    tutor_col=\"predicted_labels_tutor_msg\"\n)\n\nprint(summary)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> The input DataFrame containing predicted categories for student and/or tutor. required <code>student_col</code> <code>str</code> or <code>None</code> Name of the column with student-predicted labels. Optional. <code>None</code> <code>tutor_col</code> <code>str</code> or <code>None</code> Name of the column with tutor-predicted labels. Optional. <code>None</code> <p>Returns:</p> Name Type Description <code>summary_df</code> <code>DataFrame</code> A summary table with counts and percentages for each predicted category. Splits by student and tutor (if provided). Missing values are filled with 0. <p>3. Predicted Classes by Turns </p> Source code in <code>src/educhateval/descriptive_results/display_results.py</code> <pre><code>def plot_predicted_categories(\n    df,\n    student_col=None,\n    tutor_col=None,\n    use_percent=True,\n    palette=\"icefire\",\n    title=\"Predicted Category Distribution\",\n):\n    if not student_col and not tutor_col:\n        raise ValueError(\"You must provide at least one of student_col or tutor_col.\")\n\n    # Prepare long format\n    long_dfs = []\n    if student_col:\n        temp = df[[\"turn\", student_col]].copy()\n        temp[\"source\"] = \"Student\"\n        temp.rename(columns={student_col: \"predicted_label\"}, inplace=True)\n        long_dfs.append(temp)\n    if tutor_col:\n        temp = df[[\"turn\", tutor_col]].copy()\n        temp[\"source\"] = \"Tutor\"\n        temp.rename(columns={tutor_col: \"predicted_label\"}, inplace=True)\n        long_dfs.append(temp)\n\n    long_df = pd.concat(long_dfs, ignore_index=True)\n\n    all_labels = sorted(long_df[\"predicted_label\"].dropna().unique())\n    long_df[\"predicted_label\"] = pd.Categorical(\n        long_df[\"predicted_label\"], categories=all_labels, ordered=True\n    )\n\n    count_df = (\n        long_df.groupby([\"turn\", \"source\", \"predicted_label\"], observed=True)\n        .size()\n        .reset_index(name=\"count\")\n    )\n\n    if use_percent:\n        total_per_group = count_df.groupby([\"turn\", \"source\"], observed=True)[\n            \"count\"\n        ].transform(\"sum\")\n        count_df[\"value\"] = (count_df[\"count\"] / total_per_group) * 100\n        y_label = \"Occurrences (%)\"\n        fmt = lambda y, _: f\"{y:.0f}%\"\n        y_max = 100\n    else:\n        count_df[\"value\"] = count_df[\"count\"]\n        y_label = \"Number of Occurrences\"\n        fmt = lambda y, _: f\"{int(y)}\"\n        y_max = count_df[\"value\"].max() + 3\n\n    sns.set_style(\"whitegrid\")\n    g = sns.relplot(\n        data=count_df,\n        x=\"turn\",\n        y=\"value\",\n        hue=\"predicted_label\",\n        kind=\"line\",\n        col=\"source\" if student_col and tutor_col else None,\n        facet_kws={\"sharey\": True, \"sharex\": True},\n        height=4.5,\n        aspect=1.5,\n        marker=\"o\",\n        palette=palette,\n        hue_order=all_labels,\n    )\n\n    if student_col and tutor_col:\n        g.set_titles(\"{col_name} Messages\")\n    g.set_axis_labels(\"Turn\", y_label)\n\n    g.fig.subplots_adjust(right=0.85)\n    g._legend.set_bbox_to_anchor((1.12, 0.5))\n    g._legend.set_frame_on(True)\n    g._legend.set_title(\"Predicted Category\")\n\n    for ax in g.axes.flat:\n        ax.set_ylim(0, y_max)\n        ax.yaxis.set_major_formatter(mtick.FuncFormatter(fmt))\n\n    plt.suptitle(title, fontsize=15, fontweight=\"bold\", y=0.95)\n    plt.tight_layout()\n    plt.show()\n</code></pre> <p>Example usage: </p> <pre><code>plot_predicted_categories(\n        df=annotated_df,\n        student_col=\"predicted_labels_student_msg\",\n        tutor_col=\"predicted_labels_tutor_msg\",\n        title=\"Predicted Category Distribution\"\n    )\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> Input DataFrame with turn-level predicted labels for student and/or tutor. required <code>student_col</code> <code>str</code> or <code>None</code> Name of the column containing student-predicted categories. Optional. <code>None</code> <code>tutor_col</code> <code>str</code> or <code>None</code> Name of the column containing tutor-predicted categories. Optional. <code>None</code> <code>use_percent</code> <code>bool</code> Whether to plot percentage values (<code>True</code>) or raw counts (<code>False</code>). <code>True</code> <code>palette</code> <code>str</code> Color palette used for the plot. Optional. <code>\"icefire\"</code> <code>title</code> <code>str</code> Title of the plot. Optional. <code>\"Predicted Classes\"</code> <p>Returns:</p> Name Type Description \u2014 <code>None</code> Displays the plot using <code>matplotlib.pyplot.show()</code>. No object is returned. <p>4. Interaction Distribution </p> <p>Plot the distribution of predicted categories in the previous turn of the opposite agent. Both student and tutor is required.</p> Source code in <code>src/educhateval/descriptive_results/display_results.py</code> <pre><code>def plot_previous_turn_distribution(\n    df, \n    student_col=\"predicted_labels_student_msg\", \n    tutor_col=\"predicted_labels_tutor_msg\", \n    focus_agent=\"student\", \n    use_percent=True,\n    palette=\"icefire\"\n):\n    \"\"\"\n    Plot the distribution of predicted categories in the previous turn of the *opposite* agent. Both student and tutor is required.\n    \"\"\"\n\n    if not student_col or not tutor_col:\n        raise ValueError(\n                \"Both student_col and tutor_col must be provided.\"\n            )\n\n    if focus_agent not in [\"student\", \"tutor\"]:\n        raise ValueError(\"focus_agent must be either 'student' or 'tutor'.\")\n\n    if focus_agent == \"student\":\n        if not student_col or not tutor_col:\n            raise ValueError(\n                \"Both student_col and tutor_col must be provided when focus_agent='student'.\"\n            )\n        focus_col = student_col\n        opposite_col = tutor_col\n        focus_label = \"Student\"\n        opposite_label = \"Tutor\"\n    else:\n        if not student_col or not tutor_col:\n            raise ValueError(\n                \"Both student_col and tutor_col must be provided when focus_agent='tutor'.\"\n            )\n        focus_col = tutor_col\n        opposite_col = student_col\n        focus_label = \"Tutor\"\n        opposite_label = \"Student\"\n\n    # Prepare shifted column\n    df_sorted = df.sort_values(by=[\"student_id\", \"turn\"]).copy()\n    df_sorted[\"prev_opposite_label\"] = df_sorted.groupby(\"student_id\")[\n        opposite_col\n    ].shift(1)\n    df_filtered = df_sorted.dropna(subset=[focus_col, \"prev_opposite_label\"])\n\n    # Count combinations\n    grouped = (\n        df_filtered.groupby([focus_col, \"prev_opposite_label\"], observed=True)\n        .size()\n        .reset_index(name=\"count\")\n    )\n\n    if use_percent:\n        total_per_focus = grouped.groupby(focus_col, observed=True)[\"count\"].transform(\n            \"sum\"\n        )\n        grouped[\"percentage\"] = (grouped[\"count\"] / total_per_focus) * 100\n        y_col = \"percentage\"\n        y_label = f\"Category in Previous Turn for {opposite_label} (%)\"\n        fmt = lambda val: f\"{val:.0f}%\"\n    else:\n        grouped[\"percentage\"] = grouped[\"count\"]\n        y_col = \"count\"\n        y_label = f\"Category in Previous Turn for {opposite_label} (n)\"\n        fmt = lambda val: f\"{int(val)}\"\n\n    # Ensure all category combinations are represented\n    focus_vals = sorted(df_filtered[focus_col].dropna().unique())\n    prev_vals = sorted(df_filtered[\"prev_opposite_label\"].dropna().unique())\n    full_grid = pd.MultiIndex.from_product(\n        [focus_vals, prev_vals], names=[focus_col, \"prev_opposite_label\"]\n    ).to_frame(index=False)\n    grouped = full_grid.merge(\n        grouped, on=[focus_col, \"prev_opposite_label\"], how=\"left\"\n    ).fillna(0)\n    grouped[\"count\"] = grouped[\"count\"].astype(int)\n    if use_percent:\n        grouped[\"percentage\"] = (\n            grouped.groupby(focus_col)[\"count\"]\n            .transform(lambda x: x / x.sum() * 100)\n            .fillna(0)\n        )\n\n    grouped = grouped.sort_values(by=[focus_col, \"prev_opposite_label\"])\n\n    # Plot\n    sns.set_style(\"whitegrid\")\n    g = sns.catplot(\n        data=grouped,\n        x=focus_col,\n        y=y_col,\n        hue=\"prev_opposite_label\",\n        kind=\"bar\",\n        palette=palette,\n        height=6,\n        aspect=2.5,\n        dodge=True,\n        order=focus_vals,\n        hue_order=prev_vals,\n    )\n\n    # Adjust bar width\n    for patch in g.ax.patches:\n        patch.set_width(patch.get_width() * 0.9)\n\n    # Labels and title\n    g.set_axis_labels(f\"Category in Current Turn for {focus_label}\", y_label)\n    g.fig.suptitle(\n        f\"Distribution of Interactions: {focus_label} Focus\",\n        fontsize=15,\n        fontweight=\"bold\",\n        y=0.99,\n    )\n\n    if use_percent:\n        g.ax.set_ylim(0, 100)\n        g.ax.yaxis.set_major_formatter(mtick.FuncFormatter(lambda y, _: f\"{y:.0f}%\"))\n\n    # Annotate values (including 0s)\n    dodge_width = 0.8 / len(prev_vals)\n    for i, row in grouped.iterrows():\n        x_pos = focus_vals.index(row[focus_col])\n        hue_idx = prev_vals.index(row[\"prev_opposite_label\"])\n        xpos_shifted = x_pos - 0.4 + dodge_width / 2 + hue_idx * dodge_width\n        height = row[y_col]\n        g.ax.annotate(\n            fmt(height),\n            xy=(xpos_shifted, height),\n            xytext=(0, 3),\n            textcoords=\"offset points\",\n            ha=\"center\",\n            va=\"bottom\",\n            fontsize=9,\n        )\n\n    g.fig.subplots_adjust(right=0.85)\n    g._legend.set_bbox_to_anchor((1.12, 0.5))\n    g._legend.set_frame_on(True)\n    g._legend.set_title(f\"{opposite_label} Category (Turn - 1)\")\n\n    plt.tight_layout()\n    plt.show()\n</code></pre> <p>Example usage:</p> <pre><code>viz.plot_history_interaction(\n    df=annotated_df,\n    student_col=\"predicted_labels_student_msg\",\n    tutor_col=\"predicted_labels_tutor_msg\",\n    focus_agent=\"tutor\",\n    use_percent=True\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> Input DataFrame including turn-level predicted labels for both student and tutor. required <code>student_col</code> <code>str</code> or <code>None</code> Column name containing student-predicted categories. required <code>tutor_col</code> <code>str</code> or <code>None</code> Column name containing tutor-predicted categories. required <code>focus_agent</code> <code>str</code> Determines whether to analyze the student or tutor perspective. Options: \"student\" or \"tutor\". <code>\"student\"</code> <code>use_percent</code> <code>bool</code> If <code>True</code>, the y-axis will display percentages; otherwise raw counts are shown. <code>True</code> <code>palette</code> <code>str</code> Color palette used for the plot. Optional. <code>\"icefire\"</code> <p>Returns:</p> Name Type Description \u2014 <code>None</code> Displays the plot using <code>matplotlib.pyplot.show()</code>. No object is returned."},{"location":"api/api_wrap_int/","title":"Wrap Interactions","text":"<p>To initiate and wrap a dialogue between a user and LLM-tutor locally, follow this tutorial. </p> <p>Module for launching the Textual chat interface with an LM Studio-backed language model. It should be run from the command line.</p> <p>This class configures the model, system prompt, and save path, and then starts an interactive, full-screen terminal chat application using the <code>textual</code> framework. The interface supports live message streaming, styled user and assistant blocks, and automatic logging of chat history to JSON and CSV formats. </p> <p>Parameters:</p> Name Type Description Default <code>api_url</code> <code>str</code> <p>URL of the LM Studio API endpoint used for inference. Defaults to \"http://127.0.0.1:1234/v1/chat/completions\".</p> <code>'http://127.0.0.1:1234/v1/chat/completions'</code> <code>model_name</code> <code>str</code> <p>Name of the model to use in LM Studio (e.g., \"llama-3.2-3b-instruct\").</p> <code>'llama-3.2-3b-instruct'</code> <code>temperature</code> <code>float</code> <p>Sampling temperature for text generation. Controls randomness. Defaults to 0.7.</p> <code>0.7</code> <code>system_prompt</code> <code>str</code> <p>Initial system message to prime the assistant\u2019s behavior. Defaults to a helpful tutoring message.</p> <code>'You are a helpful tutor guiding a student. Answer short and concisely.'</code> <code>save_dir</code> <code>Path</code> <p>Directory for saving logged conversations as <code>.json</code> and <code>.csv</code>. Defaults to \"data/logged_dialogue_data\".</p> <code>Path('data/logged_dialogue_data')</code> <p>Methods:</p> Name Description <code>run</code> <p>Launches the Textual chat application and starts interaction with the model.</p> Source code in <code>src/educhateval/chat_ui.py</code> <pre><code>class ChatWrap:\n    \"\"\"\n    Module for launching the Textual chat interface with an LM Studio-backed language model. It should be run from the command line.\n\n    This class configures the model, system prompt, and save path, and then starts an interactive, full-screen terminal chat\n    application using the `textual` framework. The interface supports live message streaming, styled user and assistant blocks,\n    and automatic logging of chat history to JSON and CSV formats. \n\n    Parameters:\n        api_url (str): URL of the LM Studio API endpoint used for inference. Defaults to \"http://127.0.0.1:1234/v1/chat/completions\".\n        model_name (str): Name of the model to use in LM Studio (e.g., \"llama-3.2-3b-instruct\").\n        temperature (float): Sampling temperature for text generation. Controls randomness. Defaults to 0.7.\n        system_prompt (str): Initial system message to prime the assistant\u2019s behavior. Defaults to a helpful tutoring message.\n        save_dir (Path): Directory for saving logged conversations as `.json` and `.csv`. Defaults to \"data/logged_dialogue_data\".\n\n    Methods:\n        run(): Launches the Textual chat application and starts interaction with the model.\n\n\n    \"\"\"\n\n\n    def __init__(\n        self,\n        api_url: str = \"http://127.0.0.1:1234/v1/chat/completions\",\n        model_name: str = \"llama-3.2-3b-instruct\",\n        temperature: float = 0.7,\n        system_prompt: str = \"You are a helpful tutor guiding a student. Answer short and concisely.\",\n        save_dir: Path = Path(\"data/logged_dialogue_data\"),\n    ):\n        self.api_url = api_url\n        self.model_name = model_name\n        self.temperature = temperature\n        self.system_prompt = system_prompt\n        self.save_dir = save_dir\n\n        # Initialize model and conversation history\n        self.model = ChatLMStudio(\n            api_url=self.api_url,\n            model_name=self.model_name,\n            temperature=self.temperature,\n        )\n        self.chat_history = ChatHistory(\n            messages=[ChatMessage(role=\"system\", content=self.system_prompt)]\n        )\n\n    def run(self):\n        \"\"\"Launches the Textual app.\"\"\"\n        app = ChatApp(\n            model=self.model,\n            chat_history=self.chat_history,\n            chat_messages_dir=self.save_dir,\n        )\n        app.run()\n</code></pre> <p>Example Usage from Terminal:</p> <pre><code>chat-ui \\\n  --api_url http://127.0.0.1:1234/v1/chat/completions \\\n  --model llama-3.2-3b-instruct \\\n  --prompt \"You are a helpful tutor guiding a student.\" \\\n  --save_dir data/logged_dialogue_data\n\n</code></pre>"},{"location":"api/api_wrap_int/#educhateval.chat_ui.ChatWrap.run","title":"<code>run()</code>","text":"<p>Launches the Textual app.</p> Source code in <code>src/educhateval/chat_ui.py</code> <pre><code>def run(self):\n    \"\"\"Launches the Textual app.\"\"\"\n    app = ChatApp(\n        model=self.model,\n        chat_history=self.chat_history,\n        chat_messages_dir=self.save_dir,\n    )\n    app.run()\n</code></pre>"},{"location":"user_guides/frameworks/","title":"Templates","text":"<p>Several modules of the pipeline recevices customized prompts and seeds to ensure that the synthesized data mathces the setting users need to simulate. Here are such provided to illustrate how one can customize ...  </p>"},{"location":"user_guides/frameworks/#feedback-templates","title":"Feedback Templates","text":""},{"location":"user_guides/frameworks/#promtps","title":"Promtps","text":""},{"location":"user_guides/frameworks/#framework-generation-contstraint-classes","title":"Framework Generation: Contstraint Classes","text":""},{"location":"user_guides/frameworks/#synthesizing-interactions","title":"Synthesizing Interactions","text":""},{"location":"user_guides/frameworks/#seeds","title":"Seeds","text":""},{"location":"user_guides/frameworks/#synthesizing-interactions_1","title":"Synthesizing Interactions","text":""},{"location":"user_guides/frameworks/#linguistic-templates","title":"Linguistic Templates","text":"<p>This section demonstrates a pipeline configuration centered on simple linguistic interaction types, inspired by the communicative categories proposed by Wei et al. (2022). The template framework focuses on the following categories: Clarification, Question, Small Talk, and Statement. These categories reflect the communicative intent behind user inputs\u2014whether from the student or the LLM-driven tutor.</p> <p>While Clarification, Question, and Small Talk are directly derived from the study, the Statement category has been added to capture direct, informative responses that serve an answering function. It reflects utterances that do not seek new information but instead contribute content to the dialogue, as frequently observed in educational contexts.</p> <p>The goal of this setup is to expose the language model to targeted examples of interaction types it is expected to simulate. Each prompt encourages the model to produce sentences belonging to a specific category. Notably, only the Statement category involves full question\u2013answer pairs, ensuring that responses align with the discourse patterns typically found in learning environments.</p>"},{"location":"user_guides/frameworks/#framework-generation-contstraint-classes_1","title":"Framework Generation: Contstraint Classes","text":"<p>For the generation of utterances under the four categories (Clarification, Question, Small Talk and Statement), the model was provided with the following prompts:</p> <pre><code>\nprompt_dict = {\n    # CLARIFICATION\n    \"Clarification\": \"\"\"&lt;|im_start|&gt;system\nYou generate a conversational sentence that seeks clarification or context. \nIt should be polite, concise, and appropriate for an educational setting. You never repeat yourself.\n&lt;|im_end|&gt;\n\n&lt;|im_start|&gt;user\nCreate a clarification sentence.\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\nCould you explain what you meant by the term 'distributed cognition'?\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\nCreate another clarification sentence.\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\nPlease provide more details about what the assignment is asking for?    \n&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\nCreate a clarification sentence.\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\"\"\",\n\n    # SMALL TALK\n    \"Small Talk\": \"\"\"&lt;|im_start|&gt;system\nYou generate a short small talk sentence suitable in an casual setting. You never repeat yourself.\n&lt;|im_end|&gt;\n\n&lt;|im_start|&gt;user\nCreate a small talk sentence.\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\nHi, how are you?\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\nCreate another small talk sentence.\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\"\"\",\n\n    # QUESTION\n    \"Question\": \"\"\"&lt;|im_start|&gt;system\nYou generate a factual or thoughtful question that can be used in a conversation or educational setting. You never repeat the same question.\n&lt;|im_end|&gt;\n\n&lt;|im_start|&gt;user\nCreate a question.\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\nWhat is the capital of France?\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\nCreate a question.\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\nWhat is 24 times 25?\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\nCreate a question.\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\"\"\",\n\n    # STATEMENT\n    \"Statement\": \"\"\"&lt;|im_start|&gt;system\nYou are a helpful and knowledgeable assistant in an educational setting.\nYou respond to student questions in a friendly and conversational tone, aiming to explain or clarify in one sentence.\nEach response should:\n- Address the question naturally, like a tutor or teacher would.\n- Stick to one main idea or explanation per response.\n- Avoid repeating previous answers or stating obvious facts. \n- Don't write the question you are answering.\n&lt;|im_end|&gt;\n\n&lt;|im_start|&gt;user\nWhy do we need sleep?\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\nSleep helps your brain and body recover and process everything you\u2019ve learned during the day.\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\nwhat is the translation of hi how are you doing in portugese?\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\nThe translation of 'Hi, how are you doing?\" in Portuguese is: \"Oi, como voc\u00ea est\u00e1?'\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;user\nGive a new, unique one-sentence answer to a new and different question.\n&lt;|im_end|&gt;\n&lt;|im_start|&gt;assistant\"\"\",\n}\n\n</code></pre>"},{"location":"user_guides/frameworks/#synthesizing-interactions_2","title":"Synthesizing Interactions","text":""},{"location":"user_guides/frameworks/#seeds_1","title":"Seeds","text":""},{"location":"user_guides/frameworks/#synthesizing-interactions_3","title":"Synthesizing Interactions","text":""},{"location":"user_guides/frameworks/#wrap-interaction","title":"Wrap Interaction","text":"<p>While this function isn't used in any of the guides to avoid generating bias data by myself, an example of prompts for the chat tutor is here presented.</p>"},{"location":"user_guides/frameworks/#potential-prompts","title":"Potential Prompts","text":""},{"location":"user_guides/frameworks/#references","title":"References:","text":"<ul> <li>Wei, Y., Lu, W., Cheng, Q., Jiang, T., &amp; Liu, S. (2022). How humans obtain information from AI: Categorizing user messages in human-AI collaborative conversations. Information Processing &amp; Management, 59(2), 102838. https://doi.org/10.1016/j.ipm.2021.102838</li> </ul>"},{"location":"user_guides/guide/","title":"Guides","text":""},{"location":"user_guides/guide/#feedback-example","title":"Feedback Example","text":""},{"location":"user_guides/guide/#generate-label-framework","title":"Generate Label Framework","text":""},{"location":"user_guides/guide/#synthesize-interaction","title":"Synthesize Interaction","text":""},{"location":"user_guides/guide/#classify-and-predict","title":"Classify and Predict","text":""},{"location":"user_guides/guide/#visualize","title":"Visualize","text":""},{"location":"user_guides/guide/#linguistic-example","title":"Linguistic Example","text":""},{"location":"user_guides/guide/#generate-label-framework_1","title":"Generate Label Framework","text":""},{"location":"user_guides/guide/#synthesize-interaction_1","title":"Synthesize Interaction","text":""},{"location":"user_guides/guide/#classify-and-predict_1","title":"Classify and Predict","text":""},{"location":"user_guides/guide/#visualize_1","title":"Visualize","text":""},{"location":"user_guides/userguide_intro/","title":"Overview","text":"<p>This user guide presents two illustrative use cases that demonstrate the functionality and flexibility of the package, along with a set of prompt and seed templates tailored for different application settings. While no real-world data was available at the time of development, the examples are designed to showcase the pipeline's potential through simulated scenarios.</p> <p>The first use case focuses on generating feedback using a tutor-agent, emphasizing the types and structure of feedback produced. The second example adopts a more traditional setup, involving both student and tutor roles within a simplified linguistic framework. Together, these examples highlight the adaptability of the package and its applicability across a broad range of educational and conversational contexts.</p> <p>Detailed information on the available classes, functions, and configuration options can be found in the API reference.</p>"}]}